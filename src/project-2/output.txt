python TestRecommender.py
/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
----------Random Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:54<00:00, 183.29it/s]
Average reward: 0.225
Final analysis of results
Actions by count: [5008 4992]
Successrate by action: [0.01238019 0.53886218]
Mean reward by action [-0.08761981  0.43886218]
Matrix of actions vs outcomes, outcome is row, action is column
[[4946 2302]
 [  62 2690]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:30<00:00, 325.25it/s]
Average reward: -0.076
Final analysis of results
Actions by count: [80 82 77 81 72 81 80 71 89 83 69 75 93 80 88 85 72 72 83 66 85 69 81 61
 69 82 69 91 64 84 84 90 84 60 69 94 83 63 88 76 64 57 76 74 56 68 75 86
 82 86 93 87 78 76 74 88 71 75 73 74 86 89 79 71 84 86 70 73 75 81 88 73
 55 77 68 78 69 79 60 69 81 84 91 96 63 90 84 79 86 77 72 69 76 82 74 77
 87 75 77 86 82 70 77 81 67 90 84 73 68 78 73 89 76 89 81 72 82 69 87 72
 65 67 88 68 85 77 83 88 65]
Successrate by action: [0.         0.46341463 0.55844156 0.01234568 0.         0.
 0.025      0.02816901 0.         0.01204819 0.02898551 0.01333333
 0.02150538 0.0125     0.         0.01176471 0.01388889 0.
 0.02409639 0.         0.         0.05797101 0.02469136 0.
 0.01449275 0.03658537 0.02898551 0.         0.03125    0.02380952
 0.01190476 0.         0.01190476 0.05       0.02898551 0.
 0.01204819 0.01587302 0.01136364 0.         0.015625   0.
 0.01315789 0.01351351 0.05357143 0.01470588 0.01333333 0.
 0.02439024 0.01162791 0.01075269 0.01149425 0.         0.02631579
 0.04054054 0.         0.01408451 0.01333333 0.         0.
 0.01162791 0.03370787 0.01265823 0.01408451 0.02380952 0.02325581
 0.01428571 0.01369863 0.02666667 0.02469136 0.02272727 0.01369863
 0.         0.01298701 0.         0.         0.02898551 0.01265823
 0.05       0.02898551 0.01234568 0.02380952 0.         0.
 0.         0.02222222 0.04761905 0.         0.02325581 0.02597403
 0.01388889 0.01449275 0.01315789 0.01219512 0.02702703 0.01298701
 0.02298851 0.01333333 0.         0.         0.03658537 0.
 0.01298701 0.01234568 0.04477612 0.01111111 0.01190476 0.02739726
 0.01470588 0.02564103 0.02739726 0.03370787 0.02631579 0.
 0.03703704 0.         0.01219512 0.         0.03448276 0.01388889
 0.01538462 0.         0.01136364 0.         0.         0.
 0.02409639 0.05681818 0.        ]
Mean reward by action [-0.1         0.36341463  0.45844156 -0.08765432 -0.1        -0.1
 -0.075      -0.07183099 -0.1        -0.08795181 -0.07101449 -0.08666667
 -0.07849462 -0.0875     -0.1        -0.08823529 -0.08611111 -0.1
 -0.07590361 -0.1        -0.1        -0.04202899 -0.07530864 -0.1
 -0.08550725 -0.06341463 -0.07101449 -0.1        -0.06875    -0.07619048
 -0.08809524 -0.1        -0.08809524 -0.05       -0.07101449 -0.1
 -0.08795181 -0.08412698 -0.08863636 -0.1        -0.084375   -0.1
 -0.08684211 -0.08648649 -0.04642857 -0.08529412 -0.08666667 -0.1
 -0.07560976 -0.08837209 -0.08924731 -0.08850575 -0.1        -0.07368421
 -0.05945946 -0.1        -0.08591549 -0.08666667 -0.1        -0.1
 -0.08837209 -0.06629213 -0.08734177 -0.08591549 -0.07619048 -0.07674419
 -0.08571429 -0.08630137 -0.07333333 -0.07530864 -0.07727273 -0.08630137
 -0.1        -0.08701299 -0.1        -0.1        -0.07101449 -0.08734177
 -0.05       -0.07101449 -0.08765432 -0.07619048 -0.1        -0.1
 -0.1        -0.07777778 -0.05238095 -0.1        -0.07674419 -0.07402597
 -0.08611111 -0.08550725 -0.08684211 -0.08780488 -0.07297297 -0.08701299
 -0.07701149 -0.08666667 -0.1        -0.1        -0.06341463 -0.1
 -0.08701299 -0.08765432 -0.05522388 -0.08888889 -0.08809524 -0.07260274
 -0.08529412 -0.07435897 -0.07260274 -0.06629213 -0.07368421 -0.1
 -0.06296296 -0.1        -0.08780488 -0.1        -0.06551724 -0.08611111
 -0.08461538 -0.1        -0.08863636 -0.1        -0.1        -0.1
 -0.07590361 -0.04318182 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[80 44 34 80 72 81 78 69 89 82 67 74 91 79 88 84 71 72 81 66 85 65 79 61
  68 79 67 91 62 82 83 90 83 57 67 94 82 62 87 76 63 57 75 73 53 67 74 86
  80 85 92 86 78 74 71 88 70 74 73 74 85 86 78 70 82 84 69 72 73 79 86 72
  55 76 68 78 67 78 57 67 80 82 91 96 63 88 80 79 84 75 71 68 75 81 72 76
  85 74 77 86 79 70 76 80 64 89 83 71 67 76 71 86 74 89 78 72 81 69 84 71
  64 67 87 68 85 77 81 83 65]
 [ 0 38 43  1  0  0  2  2  0  1  2  1  2  1  0  1  1  0  2  0  0  4  2  0
   1  3  2  0  2  2  1  0  1  3  2  0  1  1  1  0  1  0  1  1  3  1  1  0
   2  1  1  1  0  2  3  0  1  1  0  0  1  3  1  1  2  2  1  1  2  2  2  1
   0  1  0  0  2  1  3  2  1  2  0  0  0  2  4  0  2  2  1  1  1  1  2  1
   2  1  0  0  3  0  1  1  3  1  1  2  1  2  2  3  2  0  3  0  1  0  3  1
   1  0  1  0  0  0  2  5  0]]
----------Historical2 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:30<00:00, 324.76it/s]
Average reward: 0.196
Final analysis of results
Actions by count: [5514 4486]
Successrate by action: [0.01051868 0.52429782]
Mean reward by action [-0.08948132  0.42429782]
Matrix of actions vs outcomes, outcome is row, action is column
[[5456 2134]
 [  58 2352]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
 57%|██████████████████████████████████████████                                | 5687/10000 [00:14<00:15, 286.13it/s]100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 316.80it/s]
Average reward: 0.201
Final analysis of results
Actions by count: [5566 4434    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:186: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01401365 0.53585927        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:187: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Mean reward by action [-0.08598635  0.43585927         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[5488 2058]
 [  78 2376]]
----------Historical3 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:33<00:00, 296.05it/s]
Average reward: 0.123
Final analysis of results
Actions by count: [7642 2358]
Successrate by action: [0.01164617 0.58227311]
Mean reward by action [-0.08835383  0.48227311]
Matrix of actions vs outcomes, outcome is row, action is column
[[7553  985]
 [  89 1373]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:34<00:00, 294.05it/s]
Average reward: 0.124
Final analysis of results
Actions by count: [7622 2378    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:186: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01272632 0.58200168        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:187: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Mean reward by action [-0.08727368  0.48200168         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[7525  994]
 [  97 1384]]
----------Optimistic Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
  0%|                                                                                      | 0/10000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "TestRecommender.py", line 63, in <module>
    result = test_policy(generator, policy, default_reward_function, int(n_tests))
  File "TestRecommender.py", line 14, in test_policy
    a = policy.recommend(x, exploring=0.2)
  File "/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/optimistic_recommender.py", line 37, in recommend
    if exploring > np.random.random():
NameError: name 'np' is not defined
root@ALEKS-PC:/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2# python TestRecommender.py
/root/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
----------Random Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:59<00:00, 167.85it/s]
Average reward: 0.215
Final analysis of results
Actions by count: [5033 4967]
Successrate by action: [0.01390821 0.51801892]
Mean reward by action [-0.08609179  0.41801892]
Matrix of actions vs outcomes, outcome is row, action is column
[[4963 2394]
 [  70 2573]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 314.89it/s]
Average reward: -0.072
Final analysis of results
Actions by count: [77 71 67 89 75 74 62 77 71 82 79 59 69 80 66 78 69 81 78 83 86 91 84 75
 83 67 63 61 77 69 79 93 87 74 79 84 73 67 78 93 68 90 64 83 80 79 64 89
 87 74 68 74 82 74 78 89 79 92 74 66 71 99 69 85 89 73 70 74 72 64 80 72
 81 81 94 71 89 64 82 70 75 69 81 84 73 93 61 92 66 90 73 62 85 89 80 84
 74 87 75 74 85 93 73 77 95 96 71 65 79 85 78 69 73 87 83 89 66 81 66 67
 80 81 78 80 99 74 65 82 62]
Successrate by action: [0.         0.5915493  0.53731343 0.01123596 0.01333333 0.01351351
 0.01612903 0.01298701 0.         0.03658537 0.05063291 0.03389831
 0.01449275 0.         0.01515152 0.01282051 0.05797101 0.01234568
 0.         0.01204819 0.02325581 0.02197802 0.         0.02666667
 0.01204819 0.01492537 0.07936508 0.         0.05194805 0.
 0.01265823 0.         0.01149425 0.02702703 0.01265823 0.
 0.02739726 0.         0.02564103 0.         0.01470588 0.02222222
 0.015625   0.         0.         0.05063291 0.03125    0.03370787
 0.01149425 0.09459459 0.01470588 0.02702703 0.         0.
 0.02564103 0.03370787 0.         0.02173913 0.         0.
 0.01408451 0.         0.         0.02352941 0.02247191 0.01369863
 0.02857143 0.01351351 0.02777778 0.         0.         0.01388889
 0.01234568 0.02469136 0.         0.02816901 0.01123596 0.015625
 0.         0.04285714 0.01333333 0.         0.01234568 0.01190476
 0.01369863 0.01075269 0.1147541  0.         0.01515152 0.03333333
 0.06849315 0.         0.02352941 0.04494382 0.025      0.03571429
 0.01351351 0.04597701 0.01333333 0.01351351 0.01176471 0.03225806
 0.         0.05194805 0.02105263 0.         0.04225352 0.01538462
 0.01265823 0.02352941 0.01282051 0.04347826 0.01369863 0.02298851
 0.03614458 0.03370787 0.03030303 0.         0.03030303 0.01492537
 0.         0.         0.01282051 0.         0.02020202 0.01351351
 0.04615385 0.08536585 0.03225806]
Mean reward by action [-0.1         0.4915493   0.43731343 -0.08876404 -0.08666667 -0.08648649
 -0.08387097 -0.08701299 -0.1        -0.06341463 -0.04936709 -0.06610169
 -0.08550725 -0.1        -0.08484848 -0.08717949 -0.04202899 -0.08765432
 -0.1        -0.08795181 -0.07674419 -0.07802198 -0.1        -0.07333333
 -0.08795181 -0.08507463 -0.02063492 -0.1        -0.04805195 -0.1
 -0.08734177 -0.1        -0.08850575 -0.07297297 -0.08734177 -0.1
 -0.07260274 -0.1        -0.07435897 -0.1        -0.08529412 -0.07777778
 -0.084375   -0.1        -0.1        -0.04936709 -0.06875    -0.06629213
 -0.08850575 -0.00540541 -0.08529412 -0.07297297 -0.1        -0.1
 -0.07435897 -0.06629213 -0.1        -0.07826087 -0.1        -0.1
 -0.08591549 -0.1        -0.1        -0.07647059 -0.07752809 -0.08630137
 -0.07142857 -0.08648649 -0.07222222 -0.1        -0.1        -0.08611111
 -0.08765432 -0.07530864 -0.1        -0.07183099 -0.08876404 -0.084375
 -0.1        -0.05714286 -0.08666667 -0.1        -0.08765432 -0.08809524
 -0.08630137 -0.08924731  0.0147541  -0.1        -0.08484848 -0.06666667
 -0.03150685 -0.1        -0.07647059 -0.05505618 -0.075      -0.06428571
 -0.08648649 -0.05402299 -0.08666667 -0.08648649 -0.08823529 -0.06774194
 -0.1        -0.04805195 -0.07894737 -0.1        -0.05774648 -0.08461538
 -0.08734177 -0.07647059 -0.08717949 -0.05652174 -0.08630137 -0.07701149
 -0.06385542 -0.06629213 -0.06969697 -0.1        -0.06969697 -0.08507463
 -0.1        -0.1        -0.08717949 -0.1        -0.07979798 -0.08648649
 -0.05384615 -0.01463415 -0.06774194]
Matrix of actions vs outcomes, outcome is row, action is column
[[77 29 31 88 74 73 61 76 71 79 75 57 68 80 65 77 65 80 78 82 84 89 84 73
  82 66 58 61 73 69 78 93 86 72 78 84 71 67 76 93 67 88 63 83 80 75 62 86
  86 67 67 72 82 74 76 86 79 90 74 66 70 99 69 83 87 72 68 73 70 64 80 71
  80 79 94 69 88 63 82 67 74 69 80 83 72 92 54 92 65 87 68 62 83 85 78 81
  73 83 74 73 84 90 73 73 93 96 68 64 78 83 77 66 72 85 80 86 64 81 64 66
  80 81 77 80 97 73 62 75 60]
 [ 0 42 36  1  1  1  1  1  0  3  4  2  1  0  1  1  4  1  0  1  2  2  0  2
   1  1  5  0  4  0  1  0  1  2  1  0  2  0  2  0  1  2  1  0  0  4  2  3
   1  7  1  2  0  0  2  3  0  2  0  0  1  0  0  2  2  1  2  1  2  0  0  1
   1  2  0  2  1  1  0  3  1  0  1  1  1  1  7  0  1  3  5  0  2  4  2  3
   1  4  1  1  1  3  0  4  2  0  3  1  1  2  1  3  1  2  3  3  2  0  2  1
   0  0  1  0  2  1  3  7  2]]
----------Historical2 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 371.76it/s]
Average reward: 0.204
Final analysis of results
Actions by count: [5390 4610]
Successrate by action: [0.01558442 0.52451193]
Mean reward by action [-0.08441558  0.42451193]
Matrix of actions vs outcomes, outcome is row, action is column
[[5306 2192]
 [  84 2418]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 87.86it/s]
Average reward: 0.198
Final analysis of results
Actions by count: [5539 4461    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:186: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01408196 0.52746021        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:187: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Mean reward by action [-0.08591804  0.42746021         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[5461 2108]
 [  78 2353]]
----------Historical3 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:34<00:00, 292.72it/s]
Average reward: 0.136
Final analysis of results
Actions by count: [7479 2521]
Successrate by action: [0.01377189 0.59936533]
Mean reward by action [-0.08622811  0.49936533]
Matrix of actions vs outcomes, outcome is row, action is column
[[7376 1010]
 [ 103 1511]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:33<00:00, 298.29it/s]
Average reward: 0.135
Final analysis of results
Actions by count: [7435 2565    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:186: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01116342 0.59376218        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:187: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Mean reward by action [-0.08883658  0.49376218         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan         nan         nan         nan
         nan         nan         nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[7352 1042]
 [  83 1523]]
----------Optimistic Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 370.25it/s]
Average reward: 0.390
Final analysis of results
Actions by count: [1044 8956]
Successrate by action: [0.01628352 0.53383207]
Mean reward by action [-0.08371648  0.43383207]
Matrix of actions vs outcomes, outcome is row, action is column
[[1027 4175]
 [  17 4781]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 353.28it/s]
Average reward: 0.329
Final analysis of results
Actions by count: [  23 8005   21   14   21   23   18   16   19   14   21   22   18   15
   18   23   13   21   19   18   18   16   17   21   15   14   10   17
   10    9   16    8   14   19   13   13   20   11   16   13   11   19
   15   22   13   10   17   18   20    7   10   17    9   19   12    8
   16   17   16   16   23   12   12   21   12   23   10   19   10   16
   20   11   13   11   15   19   16   20   16   14   18   11   15   13
    9   14   22   14   15   14   14   12   13   17   19   14   13   16
   13   16   13   14   10   12   20   18   26   17   13   19   19   17
   11   14   14   18   24   13   18   20   15   13   13   12   13    7
   19   14   15]
Successrate by action: [0.         0.52779513 0.66666667 0.07142857 0.         0.
 0.         0.         0.         0.07142857 0.04761905 0.04545455
 0.         0.13333333 0.         0.         0.         0.
 0.         0.         0.         0.0625     0.         0.
 0.         0.14285714 0.         0.05882353 0.2        0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0625     0.         0.09090909 0.
 0.         0.04545455 0.         0.         0.         0.05555556
 0.05       0.         0.         0.         0.         0.05263158
 0.         0.         0.         0.         0.         0.0625
 0.         0.         0.         0.04761905 0.         0.
 0.         0.         0.         0.         0.1        0.18181818
 0.07692308 0.09090909 0.         0.05263158 0.         0.
 0.         0.         0.         0.         0.2        0.
 0.11111111 0.07142857 0.13636364 0.07142857 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11764706 0.         0.
 0.         0.         0.08333333 0.07692308 0.05555556 0.
 0.         0.         0.         0.         0.         0.
 0.         0.14285714 0.        ]
Mean reward by action [-0.1         0.42779513  0.56666667 -0.02857143 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.02857143 -0.05238095 -0.05454545
 -0.1         0.03333333 -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.0375     -0.1        -0.1
 -0.1         0.04285714 -0.1        -0.04117647  0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.0375     -0.1        -0.00909091 -0.1
 -0.1        -0.05454545 -0.1        -0.1        -0.1        -0.04444444
 -0.05       -0.1        -0.1        -0.1        -0.1        -0.04736842
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.0375
 -0.1        -0.1        -0.1        -0.05238095 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1         0.          0.08181818
 -0.02307692 -0.00909091 -0.1        -0.04736842 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1         0.1        -0.1
  0.01111111 -0.02857143  0.03636364 -0.02857143 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1         0.01764706 -0.1        -0.1
 -0.1        -0.1        -0.01666667 -0.02307692 -0.04444444 -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1         0.04285714 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  23 3780    7   13   21   23   18   16   19   13   20   21   18   13
    18   23   13   21   19   18   18   15   17   21   15   12   10   16
     8    9   16    8   14   19   13   13   20   11   15   13   10   19
    15   21   13   10   17   17   19    7   10   17    9   18   12    8
    16   17   16   15   23   12   12   20   12   23   10   19   10   16
    18    9   12   10   15   18   16   20   16   14   18   11   12   13
     8   13   19   13   15   14   14   12   13   17   19   14   13   16
    13   16   13   14   10   12   20   18   26   17   13   19   19   15
    11   14   14   18   22   12   17   20   15   13   13   12   13    7
    19   12   15]
 [   0 4225   14    1    0    0    0    0    0    1    1    1    0    2
     0    0    0    0    0    0    0    1    0    0    0    2    0    1
     2    0    0    0    0    0    0    0    0    0    1    0    1    0
     0    1    0    0    0    1    1    0    0    0    0    1    0    0
     0    0    0    1    0    0    0    1    0    0    0    0    0    0
     2    2    1    1    0    1    0    0    0    0    0    0    3    0
     1    1    3    1    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    2
     0    0    0    0    2    1    1    0    0    0    0    0    0    0
     0    2    0]]
----------Homeopathic Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 356.16it/s]
Average reward: 0.052
Final analysis of results
Actions by count: [9061  939]
Successrate by action: [0.01169849 0.53887114]
Mean reward by action [-0.08830151  0.43887114]
Matrix of actions vs outcomes, outcome is row, action is column
[[8955  433]
 [ 106  506]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 10000
Testing for  10000 steps
100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:32<00:00, 310.83it/s]
Average reward: -0.005
Final analysis of results
Actions by count: [7996   24   16   14   14   23   18   15   14   19   19   19   13   18
   11   12   13   14   18   15   14   15   14   21   19   15   12   20
   17   14   18    8   15   10   15   14   13   14   15   11   20    9
   16   21   16   19   17   17   15   16   19    9   12   15   11   20
   12   11   17   18   11   17   11   14   15   22   13   12   13   13
   16   15   22    7   19    9   20   12   16   17   14   15   16   14
   17   11   17   19   15   14   17   17   18   20   22   11   17   19
   17   12   16   18   12   12   16   15   16   14   12   13   17   21
   15   11   17   16   17   18   17   17   14   25   15   17   18    9
   18   22   27]
Successrate by action: [0.01263132 0.5        0.5        0.         0.         0.
 0.05555556 0.06666667 0.07142857 0.05263158 0.         0.05263158
 0.07692308 0.         0.         0.         0.         0.
 0.         0.06666667 0.07142857 0.06666667 0.         0.
 0.         0.         0.         0.         0.05882353 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04761905 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05882353 0.05555556
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.07692308 0.         0.
 0.         0.         0.         0.         0.05       0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.09090909 0.09090909
 0.         0.         0.05882353 0.         0.125      0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.05882353 0.         0.         0.         0.         0.05882353
 0.         0.04       0.         0.         0.         0.
 0.05555556 0.04545455 0.        ]
Mean reward by action [-0.08736868  0.4         0.4        -0.1        -0.1        -0.1
 -0.04444444 -0.03333333 -0.02857143 -0.04736842 -0.1        -0.04736842
 -0.02307692 -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.03333333 -0.02857143 -0.03333333 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.04117647 -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.05238095 -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.04117647 -0.04444444
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.02307692 -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.05       -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.00909091 -0.00909091
 -0.1        -0.1        -0.04117647 -0.1         0.025      -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.04117647 -0.1        -0.1        -0.1        -0.1        -0.04117647
 -0.1        -0.06       -0.1        -0.1        -0.1        -0.1
 -0.04444444 -0.05454545 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[7895   12    8   14   14   23   17   14   13   18   19   18   12   18
    11   12   13   14   18   14   13   14   14   21   19   15   12   20
    16   14   18    8   15   10   15   14   13   14   15   11   20    9
    16   20   16   19   17   17   15   16   19    9   12   15   11   20
    12   11   16   17   11   17   11   14   15   22   13   12   13   12
    16   15   22    7   19    9   19   12   16   17   14   15   16   14
    17   11   17   19   15   14   17   17   18   20   20   10   17   19
    16   12   14   18   12   12   16   15   16   14   12   13   17   21
    15   11   16   16   17   18   17   16   14   24   15   17   18    9
    17   21   27]
 [ 101   12    8    0    0    0    1    1    1    1    0    1    1    0
     0    0    0    0    0    1    1    1    0    0    0    0    0    0
     1    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    1    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    1    1    0    0    0    0    0    0    0    0    0    1
     0    0    0    0    0    0    1    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    2    1    0    0
     1    0    2    0    0    0    0    0    0    0    0    0    0    0
     0    0    1    0    0    0    0    1    0    1    0    0    0    0
     1    1    0]]






------------------------------------------------------------------------------------------------------------
############################################################################################################
------------------------------------------------------------------------------------------------------------




in-stk5000/ml-society-science/src/project-2# python TestRecommender.py

--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests


Number of tests: 10000
Testing for  10000 steps
Average reward: 0.493
Final analysis of results
Actions by count: [1547 4115 1700   25   15   19   21   31   16   24   15   26   25   22
   18   22   21   28   28   29   27   23   21   26   24   23   19   17
   21   26   19   25   19   14   27   22   17   20   22   17   16   19
   18   17   23   20   21   19   16   21   21   22   16   18   20   22
   15   15   21   20   23   19   13   22   22   19   21   16   21   14
   21   19   22   22   19   20   27   22   22   21   31   21   22   23
   20   18   21   24   22   23   23   18   23   22   21   18   20   17
   20   22   17   24   28   17   24   25   19   23   17   17   12   19
   26   25   20   22   23   20   23   27   32   21   16   14   21   24
   18   21   15]
Successrate by action: [0.03878474 0.98420413 0.95411765 0.04       0.         0.
 0.         0.06451613 0.         0.         0.         0.
 0.04       0.         0.         0.         0.         0.
 0.03571429 0.         0.03703704 0.08695652 0.         0.03846154
 0.         0.         0.10526316 0.         0.         0.
 0.         0.04       0.         0.         0.         0.04545455
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.04761905 0.         0.         0.05555556
 0.         0.         0.         0.         0.         0.
 0.04347826 0.         0.         0.         0.         0.
 0.         0.         0.04761905 0.07142857 0.         0.10526316
 0.09090909 0.         0.         0.         0.         0.
 0.         0.04761905 0.03225806 0.         0.09090909 0.
 0.         0.05555556 0.         0.04166667 0.         0.
 0.         0.         0.08695652 0.         0.04761905 0.
 0.05       0.         0.         0.         0.05882353 0.
 0.03571429 0.         0.         0.04       0.         0.04347826
 0.         0.         0.         0.         0.03846154 0.
 0.05       0.13636364 0.         0.05       0.         0.03703704
 0.03125    0.         0.         0.         0.         0.
 0.05555556 0.04761905 0.        ]
Mean reward by action [-0.06121526  0.88420413  0.85411765 -0.06       -0.1        -0.1
 -0.1        -0.03548387 -0.1        -0.1        -0.1        -0.1
 -0.06       -0.1        -0.1        -0.1        -0.1        -0.1
 -0.06428571 -0.1        -0.06296296 -0.01304348 -0.1        -0.06153846
 -0.1        -0.1         0.00526316 -0.1        -0.1        -0.1
 -0.1        -0.06       -0.1        -0.1        -0.1        -0.05454545
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.05238095 -0.1        -0.1        -0.04444444
 -0.1        -0.1        -0.1        -0.1        -0.1        -0.1
 -0.05652174 -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.1        -0.05238095 -0.02857143 -0.1         0.00526316
 -0.00909091 -0.1        -0.1        -0.1        -0.1        -0.1
 -0.1        -0.05238095 -0.06774194 -0.1        -0.00909091 -0.1
 -0.1        -0.04444444 -0.1        -0.05833333 -0.1        -0.1
 -0.1        -0.1        -0.01304348 -0.1        -0.05238095 -0.1
 -0.05       -0.1        -0.1        -0.1        -0.04117647 -0.1
 -0.06428571 -0.1        -0.1        -0.06       -0.1        -0.05652174
 -0.1        -0.1        -0.1        -0.1        -0.06153846 -0.1
 -0.05        0.03636364 -0.1        -0.05       -0.1        -0.06296296
 -0.06875    -0.1        -0.1        -0.1        -0.1        -0.1
 -0.04444444 -0.05238095 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[1487   65   78   24   15   19   21   29   16   24   15   26   24   22
    18   22   21   28   27   29   26   21   21   25   24   23   17   17
    21   26   19   24   19   14   27   21   17   20   22   17   16   19
    18   17   23   20   21   19   16   21   20   22   16   17   20   22
    15   15   21   20   22   19   13   22   22   19   21   16   20   13
    21   17   20   22   19   20   27   22   22   20   30   21   20   23
    20   17   21   23   22   23   23   18   21   22   20   18   19   17
    20   22   16   24   27   17   24   24   19   22   17   17   12   19
    25   25   19   19   23   19   23   26   31   21   16   14   21   24
    17   20   15]
 [  60 4050 1622    1    0    0    0    2    0    0    0    0    1    0
     0    0    0    0    1    0    1    2    0    1    0    0    2    0
     0    0    0    1    0    0    0    1    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    1    0    0    1    0    0
     0    0    0    0    1    0    0    0    0    0    0    0    1    1
     0    2    2    0    0    0    0    0    0    1    1    0    2    0
     0    1    0    1    0    0    0    0    2    0    1    0    1    0
     0    0    1    0    1    0    0    1    0    1    0    0    0    0
     1    0    1    3    0    1    0    1    1    0    0    0    0    0
     1    1    0]]
Logistic Recommenders: 40


Number of tests: 20000
Testing for  20000 steps
Average reward: 0.512
Final analysis of results
Actions by count: [ 5923 12301  5221    49    57    42    49    64    51    54    47    61
    56    52    44    51    49    63    66    62    53    61    59    55
    54    47    62    51    43    59    48    62    47    35    63    44
    46    60    55    51    54    49    46    49    57    56    57    44
    47    54    56    58    40    56    51    54    45    42    52    51
    53    42    45    53    54    43    58    49    46    46    56    49
    54    50    48    57    60    66    57    44    60    55    61    56
    50    48    51    52    48    50    57    46    62    50    50    50
    55    44    39    52    44    53    59    43    56    62    45    58
    56    42    49    47    53    51    52    50    43    50    50    64
    70    56    43    54    54    60    47    45    43]
Successrate by action: [0.03275367 0.99073246 0.97471749 0.02040816 0.         0.
 0.         0.0625     0.01960784 0.01851852 0.         0.01639344
 0.01785714 0.         0.02272727 0.         0.         0.01587302
 0.03030303 0.01612903 0.01886792 0.03278689 0.         0.01818182
 0.         0.0212766  0.11290323 0.01960784 0.         0.01694915
 0.02083333 0.0483871  0.0212766  0.         0.         0.02272727
 0.         0.         0.01818182 0.01960784 0.01851852 0.02040816
 0.         0.         0.         0.07142857 0.         0.
 0.0212766  0.01851852 0.01785714 0.03448276 0.025      0.03571429
 0.         0.01851852 0.         0.02380952 0.01923077 0.03921569
 0.01886792 0.02380952 0.         0.         0.         0.04651163
 0.01724138 0.         0.02173913 0.06521739 0.         0.04081633
 0.03703704 0.         0.         0.         0.01666667 0.01515152
 0.         0.02272727 0.03333333 0.01818182 0.04918033 0.01785714
 0.         0.02083333 0.01960784 0.01923077 0.         0.
 0.         0.02173913 0.0483871  0.         0.04       0.
 0.01818182 0.02272727 0.         0.         0.06818182 0.
 0.03389831 0.         0.         0.03225806 0.         0.01724138
 0.         0.         0.02040816 0.0212766  0.01886792 0.
 0.01923077 0.06       0.         0.06       0.02       0.03125
 0.02857143 0.         0.         0.01851852 0.         0.
 0.04255319 0.08888889 0.        ]
Mean reward by action [-0.06724633  0.89073246  0.87471749 -0.07959184 -0.1        -0.1
 -0.1        -0.0375     -0.08039216 -0.08148148 -0.1        -0.08360656
 -0.08214286 -0.1        -0.07727273 -0.1        -0.1        -0.08412698
 -0.06969697 -0.08387097 -0.08113208 -0.06721311 -0.1        -0.08181818
 -0.1        -0.0787234   0.01290323 -0.08039216 -0.1        -0.08305085
 -0.07916667 -0.0516129  -0.0787234  -0.1        -0.1        -0.07727273
 -0.1        -0.1        -0.08181818 -0.08039216 -0.08148148 -0.07959184
 -0.1        -0.1        -0.1        -0.02857143 -0.1        -0.1
 -0.0787234  -0.08148148 -0.08214286 -0.06551724 -0.075      -0.06428571
 -0.1        -0.08148148 -0.1        -0.07619048 -0.08076923 -0.06078431
 -0.08113208 -0.07619048 -0.1        -0.1        -0.1        -0.05348837
 -0.08275862 -0.1        -0.07826087 -0.03478261 -0.1        -0.05918367
 -0.06296296 -0.1        -0.1        -0.1        -0.08333333 -0.08484848
 -0.1        -0.07727273 -0.06666667 -0.08181818 -0.05081967 -0.08214286
 -0.1        -0.07916667 -0.08039216 -0.08076923 -0.1        -0.1
 -0.1        -0.07826087 -0.0516129  -0.1        -0.06       -0.1
 -0.08181818 -0.07727273 -0.1        -0.1        -0.03181818 -0.1
 -0.06610169 -0.1        -0.1        -0.06774194 -0.1        -0.08275862
 -0.1        -0.1        -0.07959184 -0.0787234  -0.08113208 -0.1
 -0.08076923 -0.04       -0.1        -0.04       -0.08       -0.06875
 -0.07142857 -0.1        -0.1        -0.08148148 -0.1        -0.1
 -0.05744681 -0.01111111 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 5729   114   132    48    57    42    49    60    50    53    47    60
     55    52    43    51    49    62    64    61    52    59    59    54
     54    46    55    50    43    58    47    59    46    35    63    43
     46    60    54    50    53    48    46    49    57    52    57    44
     46    53    55    56    39    54    51    53    45    41    51    49
     52    41    45    53    54    41    57    49    45    43    56    47
     52    50    48    57    59    65    57    43    58    54    58    55
     50    47    50    51    48    50    57    45    59    50    48    50
     54    43    39    52    41    53    57    43    56    60    45    57
     56    42    48    46    52    51    51    47    43    47    49    62
     68    56    43    53    54    60    45    41    43]
 [  194 12187  5089     1     0     0     0     4     1     1     0     1
      1     0     1     0     0     1     2     1     1     2     0     1
      0     1     7     1     0     1     1     3     1     0     0     1
      0     0     1     1     1     1     0     0     0     4     0     0
      1     1     1     2     1     2     0     1     0     1     1     2
      1     1     0     0     0     2     1     0     1     3     0     2
      2     0     0     0     1     1     0     1     2     1     3     1
      0     1     1     1     0     0     0     1     3     0     2     0
      1     1     0     0     3     0     2     0     0     2     0     1
      0     0     1     1     1     0     1     3     0     3     1     2
      2     0     0     1     0     0     2     4     0]]
Logistic Recommenders: 78


Number of tests: 30000
Testing for  30000 steps
Average reward: 0.519
Final analysis of results
Actions by count: [12266 24897 10392   108   108    96    86   114    91    97    94   114
   103   103    84   101    99    96   117    98   111   104   115   101
   102    79   115   103    94    93    91   109    99    79   107    85
    90   118    88    98   106   101   109    81   105   102   103    89
    99   106    93   105    92   103    90   105    89    92    92    91
   103    78    89   100   108    96   106    88    91   106    96    90
   105    82    94   105   103   109   108    86   100    90   113   110
    97    98    99    95    93    97   106    94   114   100   106   103
   101    80    79   104    90    99    99    85   107   106    90   116
   109    94    85    98    96   101   100    98    87   107   103   118
   116   102    86   111   101   103    94    93    86]
Successrate by action: [0.03236589 0.99357352 0.98123557 0.00925926 0.         0.
 0.02325581 0.05263158 0.01098901 0.02061856 0.0212766  0.01754386
 0.00970874 0.         0.01190476 0.01980198 0.         0.01041667
 0.01709402 0.01020408 0.00900901 0.02884615 0.         0.01980198
 0.00980392 0.01265823 0.08695652 0.01941748 0.0106383  0.01075269
 0.02197802 0.02752294 0.02020202 0.         0.         0.01176471
 0.         0.00847458 0.01136364 0.01020408 0.00943396 0.00990099
 0.         0.         0.         0.05882353 0.00970874 0.
 0.01010101 0.02830189 0.01075269 0.02857143 0.01086957 0.01941748
 0.         0.01904762 0.01123596 0.02173913 0.01086957 0.02197802
 0.03883495 0.01282051 0.02247191 0.01       0.00925926 0.02083333
 0.01886792 0.         0.01098901 0.02830189 0.         0.02222222
 0.03809524 0.01219512 0.0106383  0.         0.00970874 0.02752294
 0.         0.02325581 0.02       0.03333333 0.02654867 0.00909091
 0.         0.02040816 0.05050505 0.01052632 0.01075269 0.
 0.00943396 0.0106383  0.03508772 0.02       0.05660377 0.
 0.01980198 0.025      0.         0.00961538 0.03333333 0.
 0.03030303 0.         0.         0.02830189 0.         0.00862069
 0.00917431 0.         0.01176471 0.01020408 0.01041667 0.
 0.03       0.05102041 0.         0.03738318 0.01941748 0.02542373
 0.01724138 0.         0.         0.02702703 0.         0.00970874
 0.0212766  0.11827957 0.        ]
Mean reward by action [-0.06763411  0.89357352  0.88123557 -0.09074074 -0.1        -0.1
 -0.07674419 -0.04736842 -0.08901099 -0.07938144 -0.0787234  -0.08245614
 -0.09029126 -0.1        -0.08809524 -0.08019802 -0.1        -0.08958333
 -0.08290598 -0.08979592 -0.09099099 -0.07115385 -0.1        -0.08019802
 -0.09019608 -0.08734177 -0.01304348 -0.08058252 -0.0893617  -0.08924731
 -0.07802198 -0.07247706 -0.07979798 -0.1        -0.1        -0.08823529
 -0.1        -0.09152542 -0.08863636 -0.08979592 -0.09056604 -0.09009901
 -0.1        -0.1        -0.1        -0.04117647 -0.09029126 -0.1
 -0.08989899 -0.07169811 -0.08924731 -0.07142857 -0.08913043 -0.08058252
 -0.1        -0.08095238 -0.08876404 -0.07826087 -0.08913043 -0.07802198
 -0.06116505 -0.08717949 -0.07752809 -0.09       -0.09074074 -0.07916667
 -0.08113208 -0.1        -0.08901099 -0.07169811 -0.1        -0.07777778
 -0.06190476 -0.08780488 -0.0893617  -0.1        -0.09029126 -0.07247706
 -0.1        -0.07674419 -0.08       -0.06666667 -0.07345133 -0.09090909
 -0.1        -0.07959184 -0.04949495 -0.08947368 -0.08924731 -0.1
 -0.09056604 -0.0893617  -0.06491228 -0.08       -0.04339623 -0.1
 -0.08019802 -0.075      -0.1        -0.09038462 -0.06666667 -0.1
 -0.06969697 -0.1        -0.1        -0.07169811 -0.1        -0.09137931
 -0.09082569 -0.1        -0.08823529 -0.08979592 -0.08958333 -0.1
 -0.07       -0.04897959 -0.1        -0.06261682 -0.08058252 -0.07457627
 -0.08275862 -0.1        -0.1        -0.07297297 -0.1        -0.09029126
 -0.0787234   0.01827957 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[11869   160   195   107   108    96    84   108    90    95    92   112
    102   103    83    99    99    95   115    97   110   101   115    99
    101    78   105   101    93    92    89   106    97    79   107    84
     90   117    87    97   105   100   109    81   105    96   102    89
     98   103    92   102    91   101    90   103    88    90    91    89
     99    77    87    99   107    94   104    88    90   103    96    88
    101    81    93   105   102   106   108    84    98    87   110   109
     97    96    94    94    92    97   105    93   110    98   100   103
     99    78    79   103    87    99    96    85   107   103    90   115
    108    94    84    97    95   101    97    93    87   103   101   115
    114   102    86   108   101   102    92    82    86]
 [  397 24737 10197     1     0     0     2     6     1     2     2     2
      1     0     1     2     0     1     2     1     1     3     0     2
      1     1    10     2     1     1     2     3     2     0     0     1
      0     1     1     1     1     1     0     0     0     6     1     0
      1     3     1     3     1     2     0     2     1     2     1     2
      4     1     2     1     1     2     2     0     1     3     0     2
      4     1     1     0     1     3     0     2     2     3     3     1
      0     2     5     1     1     0     1     1     4     2     6     0
      2     2     0     1     3     0     3     0     0     3     0     1
      1     0     1     1     1     0     3     5     0     4     2     3
      2     0     0     3     0     1     2    11     0]]
Logistic Recommenders: 97


Number of tests: 40000
Testing for  40000 steps
Average reward: 0.515
Final analysis of results
Actions by count: [21014 41567 17140   168   156   156   143   159   138   164   147   176
   159   160   153   172   157   171   192   159   180   155   178   169
   168   135   171   155   156   155   157   176   161   150   167   162
   146   198   157   164   177   163   187   156   172   161   162   160
   172   164   162   168   144   164   144   170   143   146   164   149
   183   152   148   164   163   172   165   152   140   161   156   153
   160   146   147   168   158   174   181   145   155   164   166   172
   159   165   155   161   153   167   169   149   167   163   162   176
   177   125   133   163   148   151   163   159   176   161   148   182
   181   140   154   157   169   153   160   173   153   159   158   171
   165   167   152   167   170   162   156   153   164]
Successrate by action: [0.0345484  0.99461111 0.98436406 0.01190476 0.         0.01282051
 0.02797203 0.03773585 0.00724638 0.02439024 0.02040816 0.02272727
 0.01257862 0.         0.0130719  0.01162791 0.00636943 0.01169591
 0.02083333 0.01257862 0.01111111 0.02580645 0.         0.01183432
 0.01785714 0.01481481 0.06432749 0.01290323 0.01923077 0.00645161
 0.01910828 0.01704545 0.02484472 0.01333333 0.01197605 0.01234568
 0.         0.00505051 0.00636943 0.00609756 0.00564972 0.01840491
 0.         0.00641026 0.         0.03726708 0.00617284 0.0125
 0.01162791 0.02439024 0.01851852 0.0297619  0.00694444 0.02439024
 0.         0.01176471 0.00699301 0.03424658 0.01829268 0.02684564
 0.02185792 0.01315789 0.01351351 0.00609756 0.01226994 0.01162791
 0.01818182 0.01315789 0.00714286 0.02484472 0.         0.0130719
 0.025      0.01369863 0.01360544 0.01190476 0.00632911 0.02298851
 0.01657459 0.0137931  0.02580645 0.02439024 0.02409639 0.01162791
 0.         0.01212121 0.0516129  0.01242236 0.0130719  0.01197605
 0.01183432 0.01342282 0.04790419 0.01840491 0.03703704 0.
 0.02259887 0.016      0.0075188  0.01840491 0.02027027 0.
 0.02453988 0.         0.01136364 0.02484472 0.02027027 0.00549451
 0.00552486 0.01428571 0.02597403 0.02547771 0.01183432 0.
 0.025      0.04046243 0.00653595 0.02515723 0.01898734 0.01754386
 0.01818182 0.         0.00657895 0.01796407 0.01176471 0.00617284
 0.02564103 0.10457516 0.        ]
Mean reward by action [-0.0654516   0.89461111  0.88436406 -0.08809524 -0.1        -0.08717949
 -0.07202797 -0.06226415 -0.09275362 -0.07560976 -0.07959184 -0.07727273
 -0.08742138 -0.1        -0.0869281  -0.08837209 -0.09363057 -0.08830409
 -0.07916667 -0.08742138 -0.08888889 -0.07419355 -0.1        -0.08816568
 -0.08214286 -0.08518519 -0.03567251 -0.08709677 -0.08076923 -0.09354839
 -0.08089172 -0.08295455 -0.07515528 -0.08666667 -0.08802395 -0.08765432
 -0.1        -0.09494949 -0.09363057 -0.09390244 -0.09435028 -0.08159509
 -0.1        -0.09358974 -0.1        -0.06273292 -0.09382716 -0.0875
 -0.08837209 -0.07560976 -0.08148148 -0.0702381  -0.09305556 -0.07560976
 -0.1        -0.08823529 -0.09300699 -0.06575342 -0.08170732 -0.07315436
 -0.07814208 -0.08684211 -0.08648649 -0.09390244 -0.08773006 -0.08837209
 -0.08181818 -0.08684211 -0.09285714 -0.07515528 -0.1        -0.0869281
 -0.075      -0.08630137 -0.08639456 -0.08809524 -0.09367089 -0.07701149
 -0.08342541 -0.0862069  -0.07419355 -0.07560976 -0.07590361 -0.08837209
 -0.1        -0.08787879 -0.0483871  -0.08757764 -0.0869281  -0.08802395
 -0.08816568 -0.08657718 -0.05209581 -0.08159509 -0.06296296 -0.1
 -0.07740113 -0.084      -0.0924812  -0.08159509 -0.07972973 -0.1
 -0.07546012 -0.1        -0.08863636 -0.07515528 -0.07972973 -0.09450549
 -0.09447514 -0.08571429 -0.07402597 -0.07452229 -0.08816568 -0.1
 -0.075      -0.05953757 -0.09346405 -0.07484277 -0.08101266 -0.08245614
 -0.08181818 -0.1        -0.09342105 -0.08203593 -0.08823529 -0.09382716
 -0.07435897  0.00457516 -0.1       ]
Matrix of actions vs outcomes, outcome is row, action is column
[[20288   224   268   166   156   154   139   153   137   160   144   172
    157   160   151   170   156   169   188   157   178   151   178   167
    165   133   160   153   153   154   154   173   157   148   165   160
    146   197   156   163   176   160   187   155   172   155   161   158
    170   160   159   163   143   160   144   168   142   141   161   145
    179   150   146   163   161   170   162   150   139   157   156   151
    156   144   145   166   157   170   178   143   151   160   162   170
    159   163   147   159   151   165   167   147   159   160   156   176
    173   123   132   160   145   151   159   159   174   157   145   181
    180   138   150   153   167   153   156   166   152   155   155   168
    162   167   151   164   168   161   152   137   164]
 [  726 41343 16872     2     0     2     4     6     1     4     3     4
      2     0     2     2     1     2     4     2     2     4     0     2
      3     2    11     2     3     1     3     3     4     2     2     2
      0     1     1     1     1     3     0     1     0     6     1     2
      2     4     3     5     1     4     0     2     1     5     3     4
      4     2     2     1     2     2     3     2     1     4     0     2
      4     2     2     2     1     4     3     2     4     4     4     2
      0     2     8     2     2     2     2     2     8     3     6     0
      4     2     1     3     3     0     4     0     2     4     3     1
      1     2     4     4     2     0     4     7     1     4     3     3
      3     0     1     3     2     1     4    16     0]]
Logistic Recommenders: 114






-------------------------------------------------------------------------------------------------------
########################################################################################################
-----------------------------------------------------------------------------------------------------------





in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[1 0 1 2 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 2 2 1 1 1 1 1 1 4 1 2 1 1 0 2 3 2
  1 1 1 2 1 1 1 1 3 1 1 1 2 1 1 1 1 1 1 1 1 1 1 4 2 1 0 2 1 1 1 2 3 0]
 [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
  0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 651.06it/s]
Average reward: -0.070
Final analysis of results
Actions by count: [4 3 4 3 4 4 6 6 4 7 5 7 4 4 6 3 2 4 6 0 3 5 7 4 2 3 7 7 3 3 2 2 2 5 3 3 5
 5 1 2 2 3 5 1 4 4 3 2 2 2 2 5 1 2 2 1 5 6 1 2 3 2 4 4 3 9 5 4 7 4 4 5 3 2
 2 3 7 4 3 5 9 3 2 5 6 4 6 1 4 7 3 1 5 1 2 4 1 2 4 2 1 3 4 4 3 8 2 1 3 5 8
 5 4 3 3 5 4 3 4 2 3 3 1 3 4 7 4 2 3]
Successrate by action: [0.         0.66666667 0.25       0.         0.         0.
 0.         0.         0.         0.         0.         0.14285714
 0.         0.         0.         0.         0.         0.
 0.                nan 0.         0.         0.         0.
 0.         0.         0.14285714 0.         0.         0.33333333
 0.         0.         0.         0.         0.         0.
 0.         0.4        0.         0.         0.         0.
 0.         0.         0.         0.25       0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.25       0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.2
 0.         0.         0.         0.         0.         0.14285714
 0.         0.         0.4        0.         0.         0.
 0.         0.         0.         0.         0.         0.33333333
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.33333333 0.         0.         0.         0.         0.
 0.         0.         0.         0.33333333 0.         0.
 0.25       0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[4 1 3 3 4 4 6 6 4 7 5 6 4 4 6 3 2 4 6 3 5 7 4 2 3 6 7 3 2 2 2 2 5 3 3 5
  3 1 2 2 3 5 1 4 3 3 2 2 2 2 5 1 2 2 1 5 6 1 2 3 2 3 4 3 9 5 4 7 4 4 5 3
  2 2 3 7 4 3 5 9 3 2 4 6 4 6 1 4 6 3 1 3 1 2 4 1 2 4 2 1 2 4 4 3 8 2 1 3
  5 8 5 4 3 2 5 4 3 4 2 3 3 1 2 4 7 3 2 3]
 [0 2 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0
  2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
  0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 565.65it/s]
Average reward: -0.068
Final analysis of results
Actions by count: [14 14 15 13 21 13 20 17 16 21 16 18 17 20 18 14 11 17 21 15 19 12 22 20
 11  9 16 14 11 12 27  9 15 11  8 13 20 16 10 16 12 13 14 14 11 18 15 15
 15 16 12 22  9 12  9 10 15 17 11 10 18  9 14 14 12 22 15 11 20 20 16 14
 10 17 11 19 13 15 14 12 16 13 12 18 18 11 18 15 14 17 16 15 20 13 16 15
 11  8 17 12 15 17  9 19 12 14 14 14 11 15 22 14 13 12 13 16 16 16 18  9
  9  6 12 13 20 20 15 10 10]
Successrate by action: [0.07142857 0.64285714 0.13333333 0.07692308 0.         0.
 0.         0.         0.         0.         0.         0.05555556
 0.         0.         0.05555556 0.         0.         0.11764706
 0.04761905 0.         0.         0.         0.09090909 0.
 0.         0.11111111 0.125      0.         0.         0.08333333
 0.         0.         0.2        0.         0.         0.
 0.05       0.125      0.1        0.         0.         0.
 0.         0.07142857 0.09090909 0.11111111 0.         0.06666667
 0.         0.         0.         0.04545455 0.         0.
 0.         0.         0.06666667 0.         0.09090909 0.
 0.         0.         0.07142857 0.         0.         0.
 0.06666667 0.         0.         0.         0.         0.
 0.         0.         0.18181818 0.05263158 0.         0.
 0.         0.         0.         0.         0.         0.05555556
 0.         0.         0.11111111 0.13333333 0.         0.05882353
 0.0625     0.         0.1        0.         0.         0.06666667
 0.         0.125      0.         0.         0.         0.05882353
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.07692308 0.         0.         0.         0.         0.11111111
 0.         0.         0.08333333 0.07692308 0.         0.
 0.06666667 0.1        0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[13  5 13 12 21 13 20 17 16 21 16 17 17 20 17 14 11 15 20 15 19 12 20 20
  11  8 14 14 11 11 27  9 12 11  8 13 19 14  9 16 12 13 14 13 10 16 15 14
  15 16 12 21  9 12  9 10 14 17 10 10 18  9 13 14 12 22 14 11 20 20 16 14
  10 17  9 18 13 15 14 12 16 13 12 17 18 11 16 13 14 16 15 15 18 13 16 14
  11  7 17 12 15 16  9 19 12 14 14 14 11 15 22 14 13 12 12 16 16 16 18  8
   9  6 11 12 20 20 14  9 10]
 [ 1  9  2  1  0  0  0  0  0  0  0  1  0  0  1  0  0  2  1  0  0  0  2  0
   0  1  2  0  0  1  0  0  3  0  0  0  1  2  1  0  0  0  0  1  1  2  0  1
   0  0  0  1  0  0  0  0  1  0  1  0  0  0  1  0  0  0  1  0  0  0  0  0
   0  0  2  1  0  0  0  0  0  0  0  1  0  0  2  2  0  1  1  0  2  0  0  1
   0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1
   0  0  1  1  0  0  1  1  0]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 383.46it/s]
Average reward: -0.074
Final analysis of results
Actions by count: [59 60 68 44 65 46 52 59 50 58 70 64 54 59 57 60 48 49 59 64 62 46 62 75
 56 49 62 51 56 47 79 40 63 58 48 62 55 69 61 50 52 46 54 60 61 64 57 66
 60 75 50 64 62 50 59 48 51 65 52 57 54 46 43 47 52 61 69 48 57 55 56 53
 55 59 39 69 41 64 55 53 58 45 56 68 55 63 56 55 45 68 64 59 59 46 61 46
 60 40 51 59 54 47 50 47 45 55 49 46 51 56 66 50 52 59 52 61 67 60 57 42
 55 41 49 54 60 61 54 58 58]
Successrate by action: [0.01694915 0.56666667 0.38235294 0.02272727 0.         0.
 0.         0.         0.         0.         0.01428571 0.03125
 0.         0.01694915 0.05263158 0.         0.         0.04081633
 0.03389831 0.         0.         0.02173913 0.03225806 0.01333333
 0.         0.02040816 0.03225806 0.         0.05357143 0.0212766
 0.         0.         0.04761905 0.05172414 0.         0.03225806
 0.03636364 0.02898551 0.03278689 0.02       0.03846154 0.
 0.         0.03333333 0.01639344 0.0625     0.         0.01515152
 0.         0.01333333 0.         0.046875   0.         0.
 0.01694915 0.         0.01960784 0.         0.01923077 0.01754386
 0.01851852 0.02173913 0.06976744 0.         0.03846154 0.
 0.01449275 0.         0.         0.         0.01785714 0.
 0.01818182 0.         0.05128205 0.01449275 0.         0.
 0.         0.01886792 0.01724138 0.04444444 0.         0.04411765
 0.         0.         0.08928571 0.09090909 0.         0.02941176
 0.015625   0.         0.08474576 0.02173913 0.03278689 0.02173913
 0.01666667 0.075      0.         0.01694915 0.03703704 0.0212766
 0.         0.06382979 0.         0.01818182 0.04081633 0.
 0.03921569 0.01785714 0.01515152 0.         0.         0.
 0.01923077 0.01639344 0.         0.         0.         0.04761905
 0.03636364 0.         0.02040816 0.03703704 0.01666667 0.01639344
 0.07407407 0.0862069  0.01724138]
Matrix of actions vs outcomes, outcome is row, action is column
[[58 26 42 43 65 46 52 59 50 58 69 62 54 58 54 60 48 47 57 64 62 45 60 74
  56 48 60 51 53 46 79 40 60 55 48 60 53 67 59 49 50 46 54 58 60 60 57 65
  60 74 50 61 62 50 58 48 50 65 51 56 53 45 40 47 50 61 68 48 57 55 55 53
  54 59 37 68 41 64 55 52 57 43 56 65 55 63 51 50 45 66 63 59 54 45 59 45
  59 37 51 58 52 46 50 44 45 54 47 46 49 55 65 50 52 59 51 60 67 60 57 40
  53 41 48 52 59 60 50 53 57]
 [ 1 34 26  1  0  0  0  0  0  0  1  2  0  1  3  0  0  2  2  0  0  1  2  1
   0  1  2  0  3  1  0  0  3  3  0  2  2  2  2  1  2  0  0  2  1  4  0  1
   0  1  0  3  0  0  1  0  1  0  1  1  1  1  3  0  2  0  1  0  0  0  1  0
   1  0  2  1  0  0  0  1  1  2  0  3  0  0  5  5  0  2  1  0  5  1  2  1
   1  3  0  1  2  1  0  3  0  1  2  0  2  1  1  0  0  0  1  1  0  0  0  2
   2  0  1  2  1  1  4  5  1]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:25<00:00, 16.57it/s]
Average reward: -0.072
Final analysis of results
Actions by count: [230 220 230 228 217 197 222 220 201 186 221 186 205 207 216 204 201 228
 217 215 223 203 237 221 205 211 219 208 210 210 240 174 228 220 179 236
 205 213 205 223 216 192 192 219 199 218 203 204 209 241 213 228 203 217
 207 192 202 234 209 200 187 227 200 202 195 227 233 195 200 223 206 200
 227 220 174 225 207 191 205 237 203 231 224 202 186 196 207 200 204 204
 213 198 214 202 235 207 220 201 208 207 193 195 208 193 238 244 208 198
 195 205 208 201 211 220 235 205 226 229 208 178 235 175 216 197 202 209
 222 210 221]
Successrate by action: [0.0173913  0.57727273 0.5        0.01754386 0.01382488 0.00507614
 0.03153153 0.00454545 0.00497512 0.0483871  0.01357466 0.04301075
 0.0097561  0.01932367 0.01851852 0.00490196 0.00995025 0.01754386
 0.03686636 0.02790698 0.0044843  0.01477833 0.01265823 0.01357466
 0.0097561  0.01421801 0.03196347 0.00480769 0.04285714 0.0047619
 0.00416667 0.01724138 0.03508772 0.03181818 0.         0.02966102
 0.0195122  0.01877934 0.0195122  0.01345291 0.03240741 0.00520833
 0.015625   0.02739726 0.01507538 0.03211009 0.00985222 0.00980392
 0.00478469 0.02489627 0.01408451 0.02631579 0.00492611 0.01843318
 0.02415459 0.015625   0.0049505  0.00854701 0.01435407 0.02
 0.01069519 0.00881057 0.02       0.00990099 0.04102564 0.01321586
 0.01287554 0.01025641 0.02       0.01345291 0.01941748 0.005
 0.01321586 0.01363636 0.02873563 0.02222222 0.01449275 0.0052356
 0.0195122  0.03375527 0.01477833 0.03030303 0.00892857 0.02970297
 0.00537634 0.00510204 0.04830918 0.025      0.00980392 0.01470588
 0.00469484 0.00505051 0.02803738 0.00990099 0.05531915 0.02898551
 0.01363636 0.0199005  0.00480769 0.02898551 0.03108808 0.01025641
 0.00480769 0.03108808 0.01260504 0.01229508 0.01442308 0.02525253
 0.01025641 0.02439024 0.01442308 0.03482587 0.01421801 0.01363636
 0.01276596 0.0195122  0.00442478 0.01310044 0.         0.03370787
 0.01276596 0.00571429 0.01388889 0.01522843 0.01485149 0.02392344
 0.04054054 0.09047619 0.01809955]
Matrix of actions vs outcomes, outcome is row, action is column
[[226  93 115 224 214 196 215 219 200 177 218 178 203 203 212 203 199 224
  209 209 222 200 234 218 203 208 212 207 201 209 239 171 220 213 179 229
  201 209 201 220 209 191 189 213 196 211 201 202 208 235 210 222 202 213
  202 189 201 232 206 196 185 225 196 200 187 224 230 193 196 220 202 199
  224 217 169 220 204 190 201 229 200 224 222 196 185 195 197 195 202 201
  212 197 208 200 222 201 217 197 207 201 187 193 207 187 235 241 205 193
  193 200 205 194 208 217 232 201 225 226 208 172 232 174 213 194 199 204
  213 191 217]
 [  4 127 115   4   3   1   7   1   1   9   3   8   2   4   4   1   2   4
    8   6   1   3   3   3   2   3   7   1   9   1   1   3   8   7   0   7
    4   4   4   3   7   1   3   6   3   7   2   2   1   6   3   6   1   4
    5   3   1   2   3   4   2   2   4   2   8   3   3   2   4   3   4   1
    3   3   5   5   3   1   4   8   3   7   2   6   1   1  10   5   2   3
    1   1   6   2  13   6   3   4   1   6   6   2   1   6   3   3   3   5
    2   5   3   7   3   3   3   4   1   3   0   6   3   1   3   3   3   5
    9  19   4]]
----------Historical2 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 692.33it/s]
Average reward: 0.176
Final analysis of results
Actions by count: [56 44]
Successrate by action: [0.01785714 0.47727273]
Matrix of actions vs outcomes, outcome is row, action is column
[[55 23]
 [ 1 21]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 675.80it/s]
Average reward: 0.191
Final analysis of results
Actions by count: [267 208]
Successrate by action: [0.00749064 0.51923077]
Matrix of actions vs outcomes, outcome is row, action is column
[[265 100]
 [  2 108]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 605.82it/s]
Average reward: 0.205
Final analysis of results
Actions by count: [1023  864]
Successrate by action: [0.01075269 0.52546296]
Matrix of actions vs outcomes, outcome is row, action is column
[[1012  410]
 [  11  454]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 386.72it/s]
Average reward: 0.187
Final analysis of results
Actions by count: [3983 3212]
Successrate by action: [0.01129802 0.51369863]
Matrix of actions vs outcomes, outcome is row, action is column
[[3938 1562]
 [  45 1650]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:22<00:00, 18.76it/s]
Average reward: 0.194
Final analysis of results
Actions by count: [14980 12167]
Successrate by action: [0.01188251 0.51656119]
Matrix of actions vs outcomes, outcome is row, action is column
[[14802  5882]
 [  178  6285]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 699.77it/s]
Average reward: 0.259
Final analysis of results
Actions by count: [49 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0]
Successrate by action: [0.02040816 0.58823529        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[48 21]
 [ 1 30]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 690.41it/s]
Average reward: 0.214
Final analysis of results
Actions by count: [248 227   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0]
Successrate by action: [0.02016129 0.54625551        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[243 103]
 [  5 124]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 526.91it/s]
Average reward: 0.179
Final analysis of results
Actions by count: [1032  855    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
Successrate by action: [0.01937984 0.49707602        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[1012  430]
 [  20  425]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 394.04it/s]
Average reward: 0.202
Final analysis of results
Actions by count: [3933 3262    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
Successrate by action: [0.01245868 0.52452483        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[3884 1551]
 [  49 1711]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:19<00:00, 15.68it/s]
Average reward: 0.201
Final analysis of results
Actions by count: [14804 12343     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0]
Successrate by action: [0.01107809 0.52839666        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[14640  5821]
 [  164  6522]]
----------Historical3 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.
  "of iterations.", ConvergenceWarning)
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 529.18it/s]
Average reward: 0.277
Final analysis of results
Actions by count: [37 63]
Successrate by action: [0.         0.53968254]
Matrix of actions vs outcomes, outcome is row, action is column
[[37 29]
 [ 0 34]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 636.82it/s]
Average reward: 0.247
Final analysis of results
Actions by count: [202 273]
Successrate by action: [0.00990099 0.53479853]
Matrix of actions vs outcomes, outcome is row, action is column
[[200 127]
 [  2 146]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 574.29it/s]
Average reward: 0.253
Final analysis of results
Actions by count: [ 804 1083]
Successrate by action: [0.00995025 0.53462604]
Matrix of actions vs outcomes, outcome is row, action is column
[[796 504]
 [  8 579]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:14<00:00, 370.31it/s]
Average reward: 0.252
Final analysis of results
Actions by count: [3102 4093]
Successrate by action: [0.01128304 0.53579282]
Matrix of actions vs outcomes, outcome is row, action is column
[[3067 1900]
 [  35 2193]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:23<00:00, 61.63it/s]
Average reward: 0.252
Final analysis of results
Actions by count: [11627 15520]
Successrate by action: [0.01333104 0.53170103]
Matrix of actions vs outcomes, outcome is row, action is column
[[11472  7268]
 [  155  8252]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.
  "of iterations.", ConvergenceWarning)
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 503.82it/s]
Average reward: 0.265
Final analysis of results
Actions by count: [45 55  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.04444444 0.54545455        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[43 25]
 [ 2 30]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 485.50it/s]
Average reward: 0.250
Final analysis of results
Actions by count: [209 266   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01913876 0.53759398        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[205 123]
 [  4 143]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:03<00:00, 460.02it/s]
Average reward: 0.252
Final analysis of results
Actions by count: [ 815 1072    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01104294 0.53544776        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[806 498]
 [  9 574]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:14<00:00, 356.84it/s]
Average reward: 0.246
Final analysis of results
Actions by count: [3090 4105    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01132686 0.52570037        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[3055 1947]
 [  35 2158]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:23<00:00, 61.64it/s]
Average reward: 0.251
Final analysis of results
Actions by count: [11790 15357     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.01382528 0.53174448        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[11627  7191]
 [  163  8166]]
----------Optimistic Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 674.92it/s]
Average reward: 0.442
Final analysis of results
Actions by count: [ 2 98]
Successrate by action: [0.         0.55102041]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 2 44]
 [ 0 54]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 684.15it/s]
Average reward: 0.376
Final analysis of results
Actions by count: [ 19 456]
Successrate by action: [0.05263158 0.50438596]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 18 226]
 [  1 230]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 584.51it/s]
Average reward: 0.418
Final analysis of results
Actions by count: [  98 1789]
Successrate by action: [0.01020408 0.5332588 ]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 97 835]
 [  1 954]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 383.45it/s]
Average reward: 0.421
Final analysis of results
Actions by count: [ 370 6825]
Successrate by action: [0.00540541 0.54065934]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 368 3135]
 [   2 3690]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:23<00:00, 61.71it/s]
Average reward: 0.412
Final analysis of results
Actions by count: [ 1363 25784]
Successrate by action: [0.00880411 0.53494415]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 1351 11991]
 [   12 13793]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 667.15it/s]
Average reward: 0.410
Final analysis of results
Actions by count: [ 0 92  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0
  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0
  0  0  1  0  0  0  0  0  0]
Successrate by action: [       nan 0.55434783        nan        nan        nan        nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan        nan
 0.         0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 0 41  1  1  1  1  1  1  1  1]
 [ 0 51  0  0  0  0  0  0  0  0]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 439.01it/s]
Average reward: 0.387
Final analysis of results
Actions by count: [  0 441   0   2   0   0   0   1   0   1   0   0   0   0   0   0   0   1
   0   0   0   1   0   0   1   0   1   1   1   1   0   2   0   0   0   0
   0   2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
   0   0   0   0   0   1   0   0   0   0   0   1   0   1   0   0   0   0
   0   0   0   0   0   0   1   0   1   0   0   1   0   0   0   0   0   0
   1   2   1   0   0   0   0   0   0   1   0   1   1   0   0   0   0   0
   0   0   0   0   0   0   1   1   0   1   0   0   0   1   1   0   0   0
   0   0   0]
Successrate by action: [       nan 0.53061224        nan 0.                nan        nan
        nan 0.                nan 0.                nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan 0.                nan        nan
 0.                nan 0.         0.         0.         0.
        nan 0.                nan        nan        nan        nan
        nan 0.         0.                nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan 0.
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
 0.                nan 0.                nan        nan 0.
        nan        nan        nan        nan        nan        nan
 0.         0.         0.                nan        nan        nan
        nan        nan        nan 0.                nan 0.
 0.                nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
 0.         0.                nan 0.                nan        nan
        nan 0.         0.                nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[  0 207   2   1   1   1   1   1   1   1   1   1   2   2   1   1   1   1
    1   1   1   1   2   1   1   1   1   1   1   1   1   1]
 [  0 234   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 579.16it/s]
Average reward: 0.389
Final analysis of results
Actions by count: [   0 1716    1    5    2    1    0    2    2    2    1    0    0    4
    1    2    2    1    1    3    1    4    1    1    2    0    1    2
    4    4    3    4    1    1    1    1    0    5    5    2    0    2
    3    1    0    0    0    1    1    1    0    1    0    3    2    0
    3    3    0    1    0    0    0    1    0    3    0    1    1    0
    0    3    1    2    1    0    0    0    3    0    1    1    0    1
    0    0    0    0    3    2    2    2    3    1    0    3    2    2
    0    2    2    3    2    2    0    1    0    0    1    0    0    0
    0    1    2    2    0    1    2    3    1    2    2    1    1    2
    0    1    3]
Successrate by action: [       nan 0.53613054 1.         0.         0.         0.
        nan 0.         0.         0.         0.                nan
        nan 0.         0.         0.         0.5        0.
 0.         0.         0.         0.25       0.         0.
 0.                nan 0.         0.         0.25       0.
 0.         0.         0.         0.         0.         0.
        nan 0.         0.         0.                nan 0.
 0.         0.                nan        nan        nan 0.
 0.         0.                nan 0.                nan 0.
 0.                nan 0.         0.                nan 0.
        nan        nan        nan 0.                nan 0.
        nan 0.         0.                nan        nan 0.
 0.         0.         0.                nan        nan        nan
 0.                nan 0.         0.                nan 0.
        nan        nan        nan        nan 0.         0.
 0.5        0.         0.         0.                nan 0.
 0.         0.                nan 0.         0.         0.
 0.         0.                nan 0.                nan        nan
 0.                nan        nan        nan        nan 0.
 0.         0.                nan 0.         0.         0.
 0.         0.         0.         0.         0.         0.
        nan 0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  0 796   0   5   2   1   2   2   2   1   4   1   2   1   1   1   3   1
    3   1   1   2   1   2   3   4   3   4   1   1   1   1   5   5   2   2
    3   1   1   1   1   1   3   2   3   3   1   1   3   1   1   3   1   2
    1   3   1   1   1   3   2   1   2   3   1   3   2   2   2   2   3   2
    2   1   1   1   2   2   1   2   3   1   2   2   1   1   2   1   3]
 [  0 920   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0
    1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 385.34it/s]
Average reward: 0.372
Final analysis of results
Actions by count: [   4 6463    5   11    7    2    6    7    9    5    4    5    4    9
    3    8    5    4    6    6    4    5    5   10    6    5    5    5
    9    8    6    7    8    5    7    6    4   11   11    5    3    6
    8    3    2    8    5    7    5    6    5    3    3   11    6    4
   11    9    3    9    1    5    3    8    3    7    5    2    3    2
    8    3    4    8    9    2    2    2    7    4    3    6    5    5
    3    4    5    5   10    4    7    5    6    6    4    8    8    2
    5    7    4    8   12    9    5    3    5    6    5    3    6    2
    5    5    4    6    4    9    6   11    7    8    4    7    3   11
    3    7    9]
Successrate by action: [0.         0.52792821 0.6        0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.25       0.2        0.
 0.         0.         0.         0.2        0.         0.
 0.         0.         0.         0.         0.11111111 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.125      0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25       0.         0.         0.         0.11111111
 0.         0.         0.         0.25       0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.25       0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.14285714 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.08333333 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.11111111 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[   4 3051    2   11    7    2    6    7    9    5    4    5    4    9
     3    6    4    4    6    6    4    4    5   10    6    5    5    5
     8    8    6    7    8    5    7    6    4   11   11    5    3    6
     7    3    2    8    5    7    5    6    5    3    3   11    6    3
    11    9    3    8    1    5    3    6    3    7    5    2    3    2
     8    3    4    8    9    2    2    2    7    3    3    6    5    5
     3    4    5    5   10    4    6    5    6    6    4    8    8    2
     5    7    4    8   11    9    5    3    5    6    5    3    6    2
     5    5    4    6    4    8    6   11    7    8    4    7    3   11
     3    7    9]
 [   0 3412    3    0    0    0    0    0    0    0    0    0    0    0
     0    2    1    0    0    0    0    1    0    0    0    0    0    0
     1    0    0    0    0    0    0    0    0    0    0    0    0    0
     1    0    0    0    0    0    0    0    0    0    0    0    0    1
     0    0    0    1    0    0    0    2    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    1    0    0    0    0
     0    0    0    0    0    0    1    0    0    0    0    0    0    0
     0    0    0    0    1    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    1    0    0    0    0    0    0    0    0
     0    0    0]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:30<00:00, 60.40it/s]
Average reward: 0.390
Final analysis of results
Actions by count: [   28 24430    19    19    18    17    17    21    34    21    17    21
    11    23    18    34    22    18    29    23    18    19    17    30
    22    16    17    18    22    22    21    23    23    26    24    26
    21    31    29    23    15    27    30    16    19    26    15    35
    19    23    18    18    11    23    21    23    25    21    20    23
     9    22    20    27    23    31    16    16    19    17    21    21
    22    22    20    17    28    17    27    16    15    23    19    13
    21    25    19    22    18    15    25    16    19    27    13    24
    25    20    25    17    17    23    26    24    15    17    17    22
    19    20    21    15    25    18    18    22    21    26    21    24
    21    23    19    24    20    31    28    25    17]
Successrate by action: [0.07142857 0.53786328 0.57894737 0.         0.         0.
 0.         0.         0.         0.04761905 0.         0.
 0.         0.         0.16666667 0.05882353 0.04545455 0.
 0.03448276 0.         0.         0.05263158 0.05882353 0.03333333
 0.         0.         0.         0.         0.09090909 0.
 0.         0.         0.04347826 0.03846154 0.         0.
 0.         0.09677419 0.         0.         0.         0.
 0.06666667 0.         0.         0.03846154 0.         0.
 0.05263158 0.04347826 0.         0.         0.         0.
 0.         0.04347826 0.         0.         0.1        0.08695652
 0.         0.04545455 0.05       0.14814815 0.04347826 0.
 0.         0.         0.         0.         0.         0.04761905
 0.         0.         0.05       0.05882353 0.03571429 0.
 0.03703704 0.0625     0.         0.         0.         0.
 0.         0.04       0.         0.04545455 0.         0.
 0.04       0.         0.         0.         0.         0.04166667
 0.         0.         0.         0.         0.         0.
 0.03846154 0.         0.06666667 0.         0.         0.
 0.         0.         0.         0.06666667 0.         0.
 0.         0.04545455 0.         0.03846154 0.         0.
 0.         0.04347826 0.05263158 0.04166667 0.         0.
 0.         0.16       0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[   26 11290     8    19    18    17    17    21    34    20    17    21
     11    23    15    32    21    18    28    23    18    18    16    29
     22    16    17    18    20    22    21    23    22    25    24    26
     21    28    29    23    15    27    28    16    19    25    15    35
     18    22    18    18    11    23    21    22    25    21    18    21
      9    21    19    23    22    31    16    16    19    17    21    20
     22    22    19    16    27    17    26    15    15    23    19    13
     21    24    19    21    18    15    24    16    19    27    13    23
     25    20    25    17    17    23    25    24    14    17    17    22
     19    20    21    14    25    18    18    21    21    25    21    24
     21    22    18    23    20    31    28    21    17]
 [    2 13140    11     0     0     0     0     0     0     1     0     0
      0     0     3     2     1     0     1     0     0     1     1     1
      0     0     0     0     2     0     0     0     1     1     0     0
      0     3     0     0     0     0     2     0     0     1     0     0
      1     1     0     0     0     0     0     1     0     0     2     2
      0     1     1     4     1     0     0     0     0     0     0     1
      0     0     1     1     1     0     1     1     0     0     0     0
      0     1     0     1     0     0     1     0     0     0     0     1
      0     0     0     0     0     0     1     0     1     0     0     0
      0     0     0     1     0     0     0     1     0     1     0     0
      0     1     1     1     0     0     0     4     0]]
----------Homeopathic Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 694.45it/s]
Average reward: 0.046
Final analysis of results
Actions by count: [96  4]
Successrate by action: [0.02083333 0.75      ]
Matrix of actions vs outcomes, outcome is row, action is column
[[94  1]
 [ 2  3]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 680.19it/s]
Average reward: 0.029
Final analysis of results
Actions by count: [460  15]
Successrate by action: [0.02173913 0.46666667]
Matrix of actions vs outcomes, outcome is row, action is column
[[450   8]
 [ 10   7]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 544.42it/s]
Average reward: 0.035
Final analysis of results
Actions by count: [1808   79]
Successrate by action: [0.01272124 0.63291139]
Matrix of actions vs outcomes, outcome is row, action is column
[[1785   29]
 [  23   50]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 392.52it/s]
Average reward: 0.040
Final analysis of results
Actions by count: [6809  386]
Successrate by action: [0.01248348 0.5984456 ]
Matrix of actions vs outcomes, outcome is row, action is column
[[6724  155]
 [  85  231]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:21<00:00, 18.51it/s]
Average reward: 0.031
Final analysis of results
Actions by count: [25764  1383]
Successrate by action: [0.01179941 0.5307303 ]
Matrix of actions vs outcomes, outcome is row, action is column
[[25460   649]
 [  304   734]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 666.94it/s]
Average reward: -0.013
Final analysis of results
Actions by count: [87  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  1  0  0  0  0  0
  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0
  0  0  0  1  0  0  0  0  0]
Successrate by action: [ 0. nan nan nan nan nan nan nan nan  0. nan nan  0. nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan  0. nan nan nan nan nan
 nan nan nan nan  0. nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan  0. nan nan  0. nan nan  0. nan nan nan nan nan
  0. nan nan nan nan nan nan nan  0. nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan  0. nan nan nan nan nan nan nan  0. nan nan
 nan nan nan nan nan nan nan nan nan nan  0. nan nan nan nan  0. nan nan
 nan nan nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[87  1  1  1  1  1  1  1  1  1  1  1  1  1]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 501.09it/s]
Average reward: -0.001
Final analysis of results
Actions by count: [417   0   0   0   1   0   0   0   0   1   1   0   1   0   0   0   2   1
   2   0   0   0   0   1   1   0   0   0   1   0   1   1   1   0   0   0
   0   0   0   0   2   0   1   0   0   1   1   0   0   2   0   1   0   0
   0   0   0   2   1   0   2   1   1   1   0   0   2   1   0   0   0   0
   1   0   0   0   0   0   0   0   2   0   0   1   1   0   1   0   0   0
   0   1   0   0   0   0   0   1   1   0   0   0   1   0   0   1   0   0
   0   1   0   0   0   1   0   0   1   0   1   1   0   0   1   2   3   2
   0   0   0]
Successrate by action: [0.00479616        nan        nan        nan 0.                nan
        nan        nan        nan 0.         0.                nan
 0.                nan        nan        nan 0.         0.
 0.                nan        nan        nan        nan 0.
 0.                nan        nan        nan 0.                nan
 0.         0.         0.                nan        nan        nan
        nan        nan        nan        nan 0.                nan
 0.                nan        nan 0.         0.                nan
        nan 0.                nan 0.                nan        nan
        nan        nan        nan 0.         0.                nan
 0.         0.         0.         0.                nan        nan
 0.         0.                nan        nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan 0.
 0.                nan 0.                nan        nan        nan
        nan 0.                nan        nan        nan        nan
        nan 0.         0.                nan        nan        nan
 0.                nan        nan 0.                nan        nan
        nan 1.                nan        nan        nan 1.
        nan        nan 0.                nan 0.         0.
        nan        nan 0.         0.         0.         0.
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[415   0   1   1   1   1   2   1   2   1   1   1   1   1   1   2   1   1
    1   2   1   2   1   2   1   1   1   2   1   1   2   1   1   1   1   1
    1   1   1   0   0   1   1   1   1   2   3   2]
 [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   1   1   0   0   0   0   0   0   0]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 575.29it/s]
Average reward: 0.002
Final analysis of results
Actions by count: [1712    2    0    1    1    1    0    3    3    2    3    0    1    0
    1    0    3    2    2    1    3    2    4    3    1    1    1    1
    1    0    3    2    1    1    2    0    0    0    1    0    3    1
    1    0    2    2    1    1    1    3    2    2    0    1    0    0
    0    2    3    2    2    2    1    2    3    2    2    2    1    1
    1    1    1    1    0    0    2    0    0    1    3    0    1    2
    2    2    1    0    1    0    2    3    0    2    0    1    2    2
    1    1    0    2    3    2    0    3    1    0    4    1    1    3
    1    1    1    1    3    0    1    3    1    1    1    2    4    3
    0    1    0]
Successrate by action: [0.00876168 0.5               nan 0.         0.         0.
        nan 0.         0.         0.         0.                nan
 0.                nan 0.                nan 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.                nan
 0.         0.         0.         0.         0.                nan
        nan        nan 0.                nan 0.         0.
 0.                nan 0.         0.         0.         0.
 0.         0.         0.         0.                nan 0.
        nan        nan        nan 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.                nan        nan 0.                nan
        nan 0.         0.                nan 0.         0.
 0.         0.         0.                nan 0.                nan
 0.         0.                nan 0.                nan 0.
 0.         0.         0.         0.                nan 0.
 0.         0.                nan 0.         0.                nan
 0.         1.         0.         0.         0.         1.
 0.         0.         0.                nan 0.         0.
 0.         0.         0.         0.         0.         0.
        nan 0.                nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[1697    1    1    1    1    3    3    2    3    1    1    3    2    2
     1    3    2    4    3    1    1    1    1    1    3    2    1    1
     2    1    3    1    1    2    2    1    1    1    3    2    2    1
     2    3    2    2    2    1    2    3    2    2    2    1    1    1
     1    1    1    2    1    3    1    2    2    2    1    1    2    3
     2    1    2    2    1    1    2    3    2    3    1    4    0    1
     3    1    0    1    1    3    1    3    1    1    1    2    4    3
     1]
 [  15    1    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    1    0
     0    0    1    0    0    0    0    0    0    0    0    0    0    0
     0]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:13<00:00, 381.19it/s]
Average reward: 0.005
Final analysis of results
Actions by count: [6508    9    5    3    4    4    6    8    6   10    4    3    5    4
    1    6    6    5   11    5    7    5    6    4    7    8    6    7
    5    4    8    6    2    6    6    3    4    4    6    1    9    4
    7    6    8    7    4    7    3    9    5    4    6    8    8    2
    2    3    4    4    5    8    6    6    9    5    8    8    5    5
    4    5    4    7    4    2    7    3    3    4    7    7    2    7
    4    8    3    7    3    4    8    8    2    7    3    2    7    3
   15    8    6    3    6    3    3    7    4    1    5    5    3    6
    7    5    3    5    5    2    3    8    6    8    2    6    5    8
    6    7    6]
Successrate by action: [0.01213891 0.66666667 0.2        0.         0.         0.
 0.16666667 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.18181818 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.28571429 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16666667 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.2        0.         0.         0.         0.2
 0.         0.2        0.         0.         0.         0.
 0.         0.         0.         0.         0.2        0.
 0.         0.14285714 0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[6429    3    4    3    4    4    5    8    6   10    4    3    5    4
     1    6    6    5    9    5    7    5    6    4    7    8    6    7
     5    4    8    6    2    6    6    3    4    4    6    1    9    4
     7    6    8    5    4    7    3    9    5    4    6    8    8    2
     2    3    4    4    5    8    5    6    9    5    8    8    5    5
     4    5    4    7    4    2    7    3    3    4    7    7    2    7
     4    8    3    7    3    4    8    8    2    7    3    2    7    3
    15    8    6    3    6    3    3    7    4    1    5    4    3    6
     7    4    3    4    5    2    3    8    6    8    2    6    4    8
     6    6    6]
 [  79    6    1    0    0    0    1    0    0    0    0    0    0    0
     0    0    0    0    2    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    2    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    1    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    1    0    0
     0    1    0    1    0    0    0    0    0    0    0    0    1    0
     0    1    0]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:29<00:00, 18.71it/s]
Average reward: 0.002
Final analysis of results
Actions by count: [24508    26    18    14    21    16    20    22    25    33    21    28
    21    17    16    18    23    21    24    17    20    17    21    24
    18    24    22    22    19    19    22    24    20    21    29    21
    25    17    19    16    32    13    20    27    23    23    24    28
    16    22    19    18    24    25    20    14    17    22    20    19
    19    22    14    20    22    24    21    29    13    17    15    23
    17    26    15    16    17    17    10    20    15    25    21    19
    20    21    16    26    24    19    21    15    18    23    26    22
    24    22    30    29    18    14    17    19    17    16    19    10
    19    31    13    25    27    25    13    18    26    19    20    26
    21    22    13    18    20    24    24    23    22]
Successrate by action: [0.01097601 0.61538462 0.55555556 0.         0.         0.
 0.1        0.         0.         0.         0.0952381  0.
 0.         0.         0.         0.05555556 0.         0.
 0.125      0.05882353 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05263158
 0.04545455 0.         0.         0.04761905 0.         0.
 0.         0.         0.         0.         0.         0.07692308
 0.         0.         0.         0.08695652 0.04166667 0.
 0.         0.         0.         0.05555556 0.         0.04
 0.         0.         0.         0.04545455 0.05       0.
 0.         0.         0.07142857 0.1        0.04545455 0.
 0.         0.         0.         0.         0.         0.04347826
 0.05882353 0.03846154 0.06666667 0.0625     0.         0.05882353
 0.         0.         0.         0.         0.         0.
 0.05       0.         0.0625     0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04545455 0.         0.         0.05555556 0.
 0.         0.         0.         0.         0.         0.
 0.         0.03225806 0.         0.         0.         0.04
 0.         0.05555556 0.         0.         0.         0.
 0.         0.         0.         0.         0.05       0.
 0.08333333 0.08695652 0.09090909]
Matrix of actions vs outcomes, outcome is row, action is column
[[24239    10     8    14    21    16    18    22    25    33    19    28
     21    17    16    17    23    21    21    16    20    17    21    24
     18    24    22    22    19    18    21    24    20    20    29    21
     25    17    19    16    32    12    20    27    23    21    23    28
     16    22    19    17    24    24    20    14    17    21    19    19
     19    22    13    18    21    24    21    29    13    17    15    22
     16    25    14    15    17    16    10    20    15    25    21    19
     19    21    15    26    24    19    21    15    18    23    26    22
     24    21    30    29    17    14    17    19    17    16    19    10
     19    30    13    25    27    24    13    17    26    19    20    26
     21    22    13    18    19    24    22    21    20]
 [  269    16    10     0     0     0     2     0     0     0     2     0
      0     0     0     1     0     0     3     1     0     0     0     0
      0     0     0     0     0     1     1     0     0     1     0     0
      0     0     0     0     0     1     0     0     0     2     1     0
      0     0     0     1     0     1     0     0     0     1     1     0
      0     0     1     2     1     0     0     0     0     0     0     1
      1     1     1     1     0     1     0     0     0     0     0     0
      1     0     1     0     0     0     0     0     0     0     0     0
      0     1     0     0     1     0     0     0     0     0     0     0
      0     1     0     0     0     1     0     1     0     0     0     0
      0     0     0     0     1     0     2     2     2]]
----------Improved Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 576.81it/s]
Average reward: 0.456
Final analysis of results
Actions by count: [46 54]
Successrate by action: [0.         0.94444444]
Matrix of actions vs outcomes, outcome is row, action is column
[[46  3]
 [ 0 51]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 566.12it/s]
Average reward: 0.474
Final analysis of results
Actions by count: [213 262]
Successrate by action: [0.02347418 0.9351145 ]
Matrix of actions vs outcomes, outcome is row, action is column
[[208  17]
 [  5 245]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:02<00:00, 493.30it/s]
Average reward: 0.424
Final analysis of results
Actions by count: [901 986]
Successrate by action: [0.01775805 0.9178499 ]
Matrix of actions vs outcomes, outcome is row, action is column
[[885  81]
 [ 16 905]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:15<00:00, 332.63it/s]
Average reward: 0.447
Final analysis of results
Actions by count: [3440 3755]
Successrate by action: [0.01337209 0.93928096]
Matrix of actions vs outcomes, outcome is row, action is column
[[3394  228]
 [  46 3527]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:33<00:00, 17.67it/s]
Average reward: 0.451
Final analysis of results
Actions by count: [13015 14132]
Successrate by action: [0.01644257 0.94735352]
Matrix of actions vs outcomes, outcome is row, action is column
[[12801   744]
 [  214 13388]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
/root/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 154.43it/s]
Average reward: 0.405
Final analysis of results
Actions by count: [45 48  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.04444444 0.91666667        nan        nan        nan        nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
        nan        nan 0.         0.                nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan 0.                nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[43  4  1  1  1  1  1  1  1]
 [ 2 44  0  0  0  0  0  0  0]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 157.19it/s]
Average reward: 0.425
Final analysis of results
Actions by count: [209 230   0   0   0   1   0   1   0   0   0   0   0   0   1   0   2   0
   1   2   1   1   0   0   1   1   0   0   0   0   0   0   0   0   1   0
   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0
   0   1   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0
   0   0   0   1   1   1   0   0   1   1   1   0   0   0   0   0   0   0
   0   0   1   1   0   0   0   1   0   1   1   0   1   1   0   0   0   0
   0   0   0   1   1   0   0   1   0   0   0   0   0   0   0   0   0   1
   0   0   0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.02870813 0.95217391        nan        nan        nan 0.
        nan 0.                nan        nan        nan        nan
        nan        nan 0.                nan 0.                nan
 0.         0.         0.         0.                nan        nan
 0.         0.                nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan 0.                nan
        nan 0.                nan        nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan 0.         0.         0.
        nan        nan 0.         0.         0.                nan
        nan        nan        nan        nan        nan        nan
        nan        nan 1.         0.                nan        nan
        nan 0.                nan 0.         0.                nan
 0.         0.                nan        nan        nan        nan
        nan        nan        nan 0.         0.                nan
        nan 1.                nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[203  11   1   1   1   2   1   2   1   1   1   1   1   2   1   1   1   1
    1   1   1   1   1   1   0   1   1   1   1   1   1   1   1   0   1]
 [  6 219   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:09<00:00, 149.67it/s]
Average reward: 0.454
Final analysis of results
Actions by count: [474 866 233   3   0   1   1   2   2   0   1   1   2   2   2   3   2   0
   1   3   5   2   4   0   1   1   0   1   2   0   0   1   1   0   4   1
   0   1   0   1   1   2   0   2   3   0   2   3   1   0   1   0   1   2
   1   1   0   1   1   1   1   1   0   0   0   1   4   5   0   1   0   0
   0   1   3   1   1   2   0   1   2   1   2   1   1   1   2   0   1   1
   1   0 160   3   0   0   2   2   0   3   3   1   3   2   1   0   2   0
   2   1   0   1   5   0   3   1   1   1   0   1   1   1   1   0   0   2
   0   2   0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.03797468 0.97344111 0.50643777 0.                nan 0.
 0.         0.         0.                nan 0.         0.
 0.         0.         0.         0.         0.                nan
 0.         0.         0.         0.         0.                nan
 0.         0.                nan 0.         0.                nan
        nan 0.         0.                nan 0.         0.
        nan 1.                nan 0.         0.         0.5
        nan 0.         0.                nan 0.         0.
 0.                nan 0.                nan 0.         0.
 0.         0.                nan 0.         0.         0.
 0.         0.                nan        nan        nan 0.
 0.         0.                nan 0.                nan        nan
        nan 0.         0.         0.         0.         0.
        nan 0.         0.         0.         0.         0.
 0.         0.         0.                nan 0.         0.
 0.                nan 0.00625    0.                nan        nan
 0.         0.                nan 0.         0.         0.
 0.         0.         0.                nan 0.                nan
 0.         0.                nan 0.         0.                nan
 0.         1.         0.         0.                nan 0.
 0.         0.         0.                nan        nan 0.
        nan 0.                nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[456  23 115   3   1   1   2   2   1   1   2   2   2   3   2   1   3   5
    2   4   1   1   1   2   1   1   4   1   0   1   1   1   2   3   2   3
    1   1   1   2   1   1   1   1   1   1   1   1   4   5   1   1   3   1
    1   2   1   2   1   2   1   1   1   2   1   1   1 159   3   2   2   3
    3   1   3   2   1   2   2   1   1   5   3   0   1   1   1   1   1   1
    2   2]
 [ 18 843 118   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0
    0   0]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:46<00:00, 113.02it/s]
Average reward: 0.557
Final analysis of results
Actions by count: [ 729 3296 1310    7    2    7    2    4    8    6    4    6    6    2
  197   80    4    3    1    4    8    6    6    8    5    6    6    1
    5   10    5    3    4    4    9    3    8   89    2    6    8  205
    3    5    6    4  125    5    3    6    3    5    5    4    6    9
    3    5    9    3    5   69    4    7    4    5    6   10    2    8
    2    5    1    4    5    3    7    9    4    2    4    3   12    6
    4    3    3    7   10    5    4    2  205    7    4    3    5    6
    1    9    9    9    8    4    5    4    5  207    7    3    5    5
   11    2    6   31    3    3    4    3    5    7    3    0    4    5
    5   69    4]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.07407407 0.98543689 0.86564885 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.00507614 0.0125     0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16666667 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.01123596 0.         0.         0.         0.00487805
 0.         0.         0.         0.         0.008      0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.01449275 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.00487805 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.00483092
 0.         0.         0.         0.         0.         0.
 0.         0.03225806 0.         0.         0.         0.
 0.         0.         0.                nan 0.         0.
 0.         0.01449275 0.        ]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[ 675   48  176    7    2    7    2    4    8    6    4    6    6    2
   196   79    4    3    1    4    8    6    6    8    5    6    5    1
     5   10    5    3    4    4    9    3    8   88    2    6    8  204
     3    5    6    4  124    5    3    6    3    5    5    4    6    9
     3    5    9    3    5   68    4    7    4    5    6   10    2    8
     2    5    1    4    5    3    7    9    4    2    4    3   12    6
     4    3    3    7   10    5    4    2  204    7    4    3    5    6
     1    9    9    9    8    4    5    4    5  206    7    3    5    5
    11    2    6   30    3    3    4    3    5    7    3    4    5    5
    68    4]
 [  54 3248 1134    0    0    0    0    0    0    0    0    0    0    0
     1    1    0    0    0    0    0    0    0    0    0    0    1    0
     0    0    0    0    0    0    0    0    0    1    0    0    0    1
     0    0    0    0    1    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    1    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    1    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    1    0    0    0    0
     0    0    0    1    0    0    0    0    0    0    0    0    0    0
     1    0]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:42<00:00, 58.30it/s]
Average reward: 0.565
Final analysis of results
Actions by count: [ 2951 12458  5143    22    24    18   204    17   100    77   317    23
    24    12   215   103   144    21    17    12    25    18    21    27
    18    20   115    20    27    26    17    63    28    17    22    19
    18   104    12    19    21   227    15    18    23    17   201    20
    19   211    23   116    19    21    15    26    21    20    31   183
    21    85    19    65    16   187    22    23    17    21    13   120
    16    17    26    17    26    24    20    14   121    17    25    20
    28    24   231    29    24    20    97   101   230    20    18    21
    20    24    17    24    22    26    25    23    18    22    15   233
    20    20   239    19    24   310    21    61    20    16    23    17
    13    27    24     9    19    20    20   112    64]
Successrate by action: [0.07251779 0.99317707 0.94827921 0.         0.         0.
 0.00490196 0.         0.01       0.02597403 0.00315457 0.
 0.         0.         0.00465116 0.00970874 0.00694444 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0173913  0.         0.         0.
 0.         0.03174603 0.         0.         0.         0.
 0.         0.00961538 0.         0.         0.         0.00881057
 0.         0.         0.         0.         0.00497512 0.
 0.         0.00473934 0.         0.00862069 0.         0.
 0.         0.         0.         0.         0.         0.00546448
 0.         0.01176471 0.         0.01538462 0.         0.00534759
 0.         0.         0.         0.         0.         0.00833333
 0.         0.         0.         0.         0.         0.04166667
 0.         0.         0.00826446 0.05882353 0.         0.
 0.         0.         0.00865801 0.         0.         0.
 0.01030928 0.01980198 0.00869565 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.00429185
 0.         0.         0.0041841  0.         0.         0.00322581
 0.         0.01639344 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.00892857 0.015625  ]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 2737    85   266    22    24    18   203    17    99    75   316    23
     24    12   214   102   143    21    17    12    25    18    21    27
     18    20   113    20    27    26    17    61    28    17    22    19
     18   103    12    19    21   225    15    18    23    17   200    20
     19   210    23   115    19    21    15    26    21    20    31   182
     21    84    19    64    16   186    22    23    17    21    13   119
     16    17    26    17    26    23    20    14   120    16    25    20
     28    24   229    29    24    20    96    99   228    20    18    21
     20    24    17    24    22    26    25    23    18    22    15   232
     20    20   238    19    24   309    21    60    20    16    23    17
     13    27    24     9    19    20    20   111    63]
 [  214 12373  4877     0     0     0     1     0     1     2     1     0
      0     0     1     1     1     0     0     0     0     0     0     0
      0     0     2     0     0     0     0     2     0     0     0     0
      0     1     0     0     0     2     0     0     0     0     1     0
      0     1     0     1     0     0     0     0     0     0     0     1
      0     1     0     1     0     1     0     0     0     0     0     1
      0     0     0     0     0     1     0     0     1     1     0     0
      0     0     2     0     0     0     1     2     2     0     0     0
      0     0     0     0     0     0     0     0     0     0     0     1
      0     0     1     0     0     1     0     1     0     0     0     0
      0     0     0     0     0     0     0     1     1]]
----------Adaptive Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 128.61it/s]
Average reward: 0.201
Final analysis of results
Actions by count: [71 29]
Successrate by action: [0.01408451 0.75862069]
Matrix of actions vs outcomes, outcome is row, action is column
[[70  7]
 [ 1 22]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 111.83it/s]
Average reward: 0.225
Final analysis of results
Actions by count: [313 162]
Successrate by action: [0.01597444 0.71604938]
Matrix of actions vs outcomes, outcome is row, action is column
[[308  46]
 [  5 116]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:10<00:00, 129.43it/s]
Average reward: 0.214
Final analysis of results
Actions by count: [1267  620]
Successrate by action: [0.01341752 0.72903226]
Matrix of actions vs outcomes, outcome is row, action is column
[[1250  168]
 [  17  452]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:50<00:00, 105.86it/s]
Average reward: 0.173
Final analysis of results
Actions by count: [5117 2078]
Successrate by action: [0.017393   0.69489894]
Matrix of actions vs outcomes, outcome is row, action is column
[[5028  634]
 [  89 1444]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:29<00:00, 60.52it/s]
Average reward: 0.123
Final analysis of results
Actions by count: [20728  6419]
Successrate by action: [0.01413547 0.64309082]
Matrix of actions vs outcomes, outcome is row, action is column
[[20435  2291]
 [  293  4128]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.24it/s]
Average reward: 0.316
Final analysis of results
Actions by count: [16 45  1  1  0  1  1  0  0  0  0  0  0  0  0  0  1  0  0  1  1  0  0  0
  1  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  0  1  2  1  0  0
  0  2  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0
  1  0  0  0  0  0  0  0  0  0  1  0  1  0  1  0  0  1  0  2  0  1  1  0
  0  0  1  1  1  0  0  1  0  0  4  0  0  0  0  0  0  0  0  2  0  0  0  0
  0  0  0  0  0  0  0  0  0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.         0.88888889 0.         0.                nan 0.
 0.                nan        nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
        nan 0.         0.                nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan 0.
        nan 0.                nan 0.                nan        nan
        nan 0.         0.         0.                nan        nan
        nan 0.                nan        nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan        nan
        nan        nan        nan        nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan        nan        nan 0.                nan
 0.                nan 0.                nan        nan 0.
        nan 0.                nan 0.         0.                nan
        nan        nan 0.         0.         0.                nan
        nan 0.                nan        nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[16  5  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  2  1  1  1  1  1  1
   1  2  1  1  1  1  1  1  4  2]
 [ 0 40  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0]]
Number of tests: 375
Testing for  375 steps
100%|██████████████████████████████████████████████████████████████████████████████| 375/375 [01:58<00:00,  3.06it/s]
Average reward: 0.154
Final analysis of results
Actions by count: [ 80 148   3   3   2   3   1   2   2   2   2   3   1   1   1   1   6   3
   1   3   4   1   1   0   6   4   3   1   2   0   2   1   4   1   6   2
   2   4   2   5   4   1   1   3   5   2   3   2   3   3   4   1   1   2
   3   0   4   2   1   3   2   1   3   2   1   0   2   2   2   1   2   0
   3   3   0   2   1   1   1   0   0   0   2   0   2   0   1   0   1   2
   3   3   0   2   1   0   2   1   1   1   2   3   2   3   5   0   5   1
   2   2   2   0   2   2   1   3   4   0   5   1   1   1   0   4   0   0
   0   4   2]
Successrate by action: [0.         0.86486486 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.33333333
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.                nan
 0.         0.         0.         0.         0.                nan
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.                nan 0.         0.         0.         0.
 0.         0.         0.         0.         0.                nan
 0.         0.         0.         0.         0.                nan
 0.         0.                nan 0.         0.         0.
 0.                nan        nan        nan 0.                nan
 0.                nan 0.                nan 0.         0.
 0.         0.                nan 0.         0.                nan
 0.         0.         0.         0.         0.         0.
 0.         0.         0.                nan 0.         0.
 0.         0.         0.                nan 0.         0.
 0.         0.         0.                nan 0.         0.
 0.         0.                nan 0.                nan        nan
        nan 0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 80  20   3   3   2   3   1   2   2   2   2   2   1   1   1   1   6   3
    1   3   4   1   1   6   4   3   1   2   2   1   4   1   6   2   2   4
    2   5   4   1   1   3   5   2   3   2   3   3   4   1   1   2   3   4
    2   1   3   2   1   3   2   1   2   2   2   1   2   3   3   2   1   1
    1   2   2   1   1   2   3   3   2   1   2   1   1   1   2   3   2   3
    5   5   1   2   2   2   2   2   1   3   4   5   1   1   1   4   4   2]
 [  0 128   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]
Number of tests: 1412
Testing for  1412 steps
100%|████████████████████████████████████████████████████████████████████████████| 1412/1412 [07:50<00:00,  2.99it/s]
Average reward: 0.173
Final analysis of results
Actions by count: [356 557  11   7   8   8  10   7   4   6  11  11  10   9   4   9  11  12
   6   7   8   9   8   6  10   7   8   9   6   5   9   4  12   6  10   6
   6   9   7   9   8   9   9   8   9   7  17   6   7   9  12   3  13   5
   9   9  10  16   5  10  10   4   8  11   6   6   6  10   7   7   5  10
   5   6   6  11   7   9   6   6   6   3   5   7   7   9   6   7   9   9
  11   9   3   9   6   8   3   8   5   8   7   4   6   8   8  11   9   5
  12  10  13   4   6   5   4   7   7   9  14   3   6   5   5   9   4   2
   9   7   5]
Successrate by action: [0.03651685 0.84021544 0.27272727 0.         0.         0.
 0.         0.         0.         0.         0.         0.09090909
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16666667 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.09090909 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[343  89   8   7   8   8  10   7   4   6  11  10  10   9   4   9  11  12
    6   7   8   9   8   6  10   7   8   9   6   5   9   4  12   6  10   6
    6   9   7   9   8   9   9   8   9   7  17   6   7   9  12   3  13   5
    9   9  10  16   5  10  10   4   8  11   6   6   6  10   7   7   5  10
    5   6   6  11   7   9   6   6   6   3   5   7   7   9   5   7   9   9
   11   9   3   9   6   8   3   8   5   8   7   4   6   8   8  10   9   5
   12  10  13   4   6   5   4   7   7   9  14   3   6   5   5   9   4   2
    9   7   5]
 [ 13 468   3   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]]
Number of tests: 5308
Testing for  5308 steps
100%|████████████████████████████████████████████████████████████████████████████| 5308/5308 [31:47<00:00,  2.69it/s]
Average reward: 0.271
Final analysis of results
Actions by count: [1419 1900  790   31   26   28   29   25   17   30   25   28   24   26
   24   31   33   28   22   28   25   33   24   23   31   19   26   26
   25   25   26   22   21   25   26   29   20   32   26   24   23   25
   22   23   24   19   37   24   17   27   30   20   29   24   26   25
   25   31   22   25   19   22   18   33   21   20   32   26   19   23
   22   23   21   25   15   26   26   27   22   22   18   26   24   23
   28   25   22   27   29   24   27   28   16   20   32   20   22   26
   16   22   26   19   21   25   22   27   34   21   30   29   31   21
   23   21   25   23   23   18   28   20   27   23   16   24   25   14
   31   23   18]
Successrate by action: [0.03664553 0.82157895 0.91392405 0.         0.         0.
 0.03448276 0.         0.         0.         0.         0.03571429
 0.         0.03846154 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.1        0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.05
 0.         0.         0.         0.         0.         0.
 0.         0.         0.06666667 0.         0.         0.
 0.         0.         0.         0.03846154 0.04166667 0.
 0.         0.         0.04545455 0.         0.         0.
 0.         0.         0.         0.         0.         0.05
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.03703704 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.04347826 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.07142857
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[1367  339   68   31   26   28   28   25   17   30   25   27   24   25
    24   31   33   28   22   28   25   33   24   23   31   19   26   26
    25   25   26   22   21   25   26   29   18   32   26   24   23   25
    22   23   24   19   37   24   17   27   30   20   29   24   26   25
    25   31   22   25   19   22   18   33   21   19   32   26   19   23
    22   23   21   25   14   26   26   27   22   22   18   25   23   23
    28   25   21   27   29   24   27   28   16   20   32   19   22   26
    16   22   26   19   21   25   22   26   34   21   30   29   31   21
    23   21   25   22   23   18   28   20   27   23   16   24   25   13
    31   23   18]
 [  52 1561  722    0    0    0    1    0    0    0    0    1    0    1
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    2    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    1    0    0    0    0
     0    0    0    0    1    0    0    0    0    0    0    1    1    0
     0    0    1    0    0    0    0    0    0    0    0    1    0    0
     0    0    0    0    0    0    0    1    0    0    0    0    0    0
     0    0    0    1    0    0    0    0    0    0    0    0    0    1
     0    0    0]]
Number of tests: 19952
Testing for  19952 steps
100%|████████████████████████████████████████████████████████████████████████| 19952/19952 [2:03:07<00:00,  2.64it/s]
Average reward: 0.294
Final analysis of results
Actions by count: [6724 5313 5432   87   90   89   73   79   74   79   80   89   80   80
   83   91   77   79   72   80   74   90   70   74   84   70   71   76
   69   80   78   74   72   73   79   82   71   83   79   76   71   83
   81   65   92   70   81   75   79   78   86   78   82   76   76   75
   56   83   78   82   73   69   65   83   70   73   87   83   71   99
   66   86   70   78   64   88   76   71   71   77   72   81   64   74
   78   85   84   84   76   72   70   82   78   91   82   69   71   75
   82   62   80   72   72   71   66   92   85   72   87   87   87   77
   75   70   70   67   69   69   80   68   86   76   73   64   78   62
   81   68   68]
Successrate by action: [0.041047   0.7741389  0.96410162 0.         0.         0.
 0.01369863 0.         0.01351351 0.01265823 0.         0.01123596
 0.         0.0125     0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01408451 0.         0.01449275 0.
 0.         0.         0.         0.01369863 0.01265823 0.02439024
 0.02816901 0.         0.         0.         0.         0.
 0.         0.03076923 0.         0.         0.         0.
 0.01265823 0.         0.01162791 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.01538462 0.01204819 0.         0.01369863
 0.         0.         0.         0.01010101 0.01515152 0.01162791
 0.         0.         0.015625   0.         0.         0.01408451
 0.         0.01298701 0.01388889 0.03703704 0.015625   0.
 0.         0.         0.03571429 0.         0.01315789 0.
 0.         0.         0.01282051 0.         0.         0.01449275
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.01086957 0.         0.
 0.         0.01149425 0.01149425 0.         0.         0.01428571
 0.         0.02985075 0.         0.         0.         0.
 0.         0.         0.01369863 0.         0.         0.01612903
 0.01234568 0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[6448 1200  195   87   90   89   72   79   73   78   80   88   80   79
    83   91   77   79   72   80   74   90   70   74   84   70   70   76
    68   80   78   74   72   72   78   80   69   83   79   76   71   83
    81   63   92   70   81   75   78   78   85   78   82   76   76   75
    56   83   78   82   73   69   64   82   70   72   87   83   71   98
    65   85   70   78   63   88   76   70   71   76   71   78   63   74
    78   85   81   84   75   72   70   82   77   91   82   68   71   75
    82   62   80   72   72   71   66   91   85   72   87   86   86   77
    75   69   70   65   69   69   80   68   86   76   72   64   78   61
    80   68   68]
 [ 276 4113 5237    0    0    0    1    0    1    1    0    1    0    1
     0    0    0    0    0    0    0    0    0    0    0    0    1    0
     1    0    0    0    0    1    1    2    2    0    0    0    0    0
     0    2    0    0    0    0    1    0    1    0    0    0    0    0
     0    0    0    0    0    0    1    1    0    1    0    0    0    1
     1    1    0    0    1    0    0    1    0    1    1    3    1    0
     0    0    3    0    1    0    0    0    1    0    0    1    0    0
     0    0    0    0    0    0    0    1    0    0    0    1    1    0
     0    1    0    2    0    0    0    0    0    0    1    0    0    1
     1    0    0]]
----------Adaptive2 Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 485.14it/s]
Average reward: 0.398
Final analysis of results
Actions by count: [ 8 92]
Successrate by action: [0.        0.5326087]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 8 43]
 [ 0 49]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:00<00:00, 519.83it/s]
Average reward: 0.416
Final analysis of results
Actions by count: [ 25 450]
Successrate by action: [0.04       0.53333333]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 24 210]
 [  1 240]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:03<00:00, 424.83it/s]
Average reward: 0.422
Final analysis of results
Actions by count: [ 111 1776]
Successrate by action: [0.02702703 0.54391892]
Matrix of actions vs outcomes, outcome is row, action is column
[[108 810]
 [  3 966]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:15<00:00, 344.35it/s]
Average reward: 0.424
Final analysis of results
Actions by count: [ 425 6770]
Successrate by action: [0.02352941 0.54771049]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 415 3062]
 [  10 3708]]
Number of tests: 19952
Testing for  19952 steps
100%|█████████████████████████████████████████████████████████████████████████| 19952/19952 [03:16<00:00, 101.72it/s]
Average reward: 0.414
Final analysis of results
Actions by count: [ 1953 25194]
Successrate by action: [0.01177675 0.54782885]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 1930 11392]
 [   23 13802]]
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 147.54it/s]
Average reward: 0.290
Final analysis of results
Actions by count: [ 0 90  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  1
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0
  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0
  0  0  0  0  0  0  0  0  0]
Successrate by action: [       nan 0.43333333        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan 0.
        nan        nan 0.                nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan 0.         0.                nan
        nan        nan        nan 0.                nan        nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 0 51  1  1  1  1  1  1  1  1  1  1]
 [ 0 39  0  0  0  0  0  0  0  0  0  0]]
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 155.03it/s]
Average reward: 0.350
Final analysis of results
Actions by count: [  0 429   0   0   0   1   0   0   0   0   0   2   1   1   0   0   0   1
   0   0   0   0   0   1   0   0   0   0   2   1   0   0   0   0   0   0
   0   1   0   0   1   0   2   0   0   0   0   0   1   0   0   1   0   0
   0   0   0   0   0   0   0   0   0   0   2   3   0   0   1   0   2   0
   0   0   0   0   0   0   0   1   1   0   1   1   0   0   0   0   0   0
   0   1   0   1   2   1   1   0   0   1   1   0   0   3   1   0   0   0
   1   1   0   0   0   0   0   0   1   0   2   0   0   0   0   1   0   0
   0   0   0]
Successrate by action: [       nan 0.48484848        nan        nan        nan 0.
        nan        nan        nan        nan        nan 0.
 0.         0.                nan        nan        nan 0.
        nan        nan        nan        nan        nan 0.
        nan        nan        nan        nan 0.         0.
        nan        nan        nan        nan        nan        nan
        nan 0.                nan        nan 0.                nan
 0.                nan        nan        nan        nan        nan
 0.                nan        nan 0.                nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan 0.         0.
        nan        nan 0.                nan 0.                nan
        nan        nan        nan        nan        nan        nan
        nan 0.         0.                nan 0.         0.
        nan        nan        nan        nan        nan        nan
        nan 0.                nan 0.         0.         0.
 0.                nan        nan 0.         0.                nan
        nan 0.         0.                nan        nan        nan
 0.         0.                nan        nan        nan        nan
        nan        nan 0.                nan 0.                nan
        nan        nan        nan 0.                nan        nan
        nan        nan        nan]
Matrix of actions vs outcomes, outcome is row, action is column
[[  0 221   1   2   1   1   1   1   2   1   1   1   2   1   1   2   3   1
    2   1   1   1   1   1   1   2   1   1   1   1   3   1   1   1   1   2
    1]
 [  0 208   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0]]
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:09<00:00, 148.04it/s]
Average reward: 0.399
Final analysis of results
Actions by count: [   1 1689    1    3    1    1    1    1    2    2    2    2    1    1
    3    2    3    2    2    1    1    1    1    1    2    2    1    3
    2    2    2    1    1    1    0    2    1    3    1    0    1    0
    4    0    1    0    2    1    4    1    1    2    5    3    0    1
    3    2    0    0    1    2    0    1    4    5    0    1    2    2
    2    0    2    2    1    3    0    3    3    1    3    1    5    2
    1    2    2    1    1    0    0    4    1    1    2    1    2    0
    1    2    2    1    0    4    2    0    2    0    1    4    0    3
    2    0    2    0    2    1    2    0    0    2    1    3    2    0
    0    2    2]
Successrate by action: [0.         0.53818828 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.                nan 0.
 0.         0.         0.                nan 0.                nan
 0.                nan 0.                nan 0.         0.
 0.         0.         0.         0.         0.         0.
        nan 0.         0.         0.                nan        nan
 0.         0.5               nan 0.         0.         0.
        nan 0.         0.         0.5        0.                nan
 0.         0.         0.         0.                nan 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.5        0.         0.                nan
        nan 0.         0.         0.         0.         0.
 0.                nan 0.         0.         0.         0.
        nan 0.         0.                nan 0.                nan
 0.         0.                nan 0.         0.                nan
 0.                nan 0.         0.         0.                nan
        nan 0.         0.         0.         0.                nan
        nan 0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  1 780   1   3   1   1   1   1   2   2   2   2   1   1   3   2   3   2
    2   1   1   1   1   1   2   2   1   3   2   2   2   1   1   1   2   1
    3   1   1   4   1   2   1   4   1   1   2   5   3   1   3   2   1   1
    1   4   5   1   2   1   2   2   2   1   3   3   3   1   3   1   5   2
    1   2   1   1   1   4   1   1   2   1   2   1   2   2   1   4   2   2
    1   4   3   2   2   2   1   2   2   1   3   2   2   2]
 [  0 909   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1
    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:46<00:00, 113.61it/s]
Average reward: 0.427
Final analysis of results
Actions by count: [  29 4200 2264    8    8    5    7    8    7    7    6    6    5    2
    5    6    7    5    7    5    6    2    5    3    6    7    8    4
    7    8    3    4    4    5    5    6    3    6    5    4   10    4
    8    3    6    5    6   10    8    4    2   12   10    7    3    5
    6    6    8    5    5    6    1    5    5    9    4    7    5    3
    6    5    5    5    9    6    4    4    6    5    9    5    7    7
    3    5    8    3    2    5    5    7    5    2    6    6    5    4
    3    6    4    5    5    9    6    5    6    5    2    7    8    5
    4    5    5    2    3    7    4    4    9   10    5    9    6    2
    5    7    7]
Successrate by action: [0.         0.54690476 0.61484099 0.         0.         0.
 0.         0.         0.         0.14285714 0.         0.
 0.         0.         0.         0.         0.14285714 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.1        0.
 0.         0.         0.16666667 0.         0.         0.1
 0.         0.25       0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.33333333 0.         0.         0.         0.
 0.25       0.         0.         0.33333333 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.375      0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.16666667 0.2
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.25
 0.         0.         0.         0.         0.         0.
 0.         0.14285714 0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  29 1903  872    8    8    5    7    8    7    6    6    6    5    2
     5    6    6    5    7    5    6    2    5    3    6    7    8    4
     7    8    3    4    4    5    5    6    3    6    5    4    9    4
     8    3    5    5    6    9    8    3    2   12   10    7    3    5
     6    6    8    5    5    4    1    5    5    9    3    7    5    2
     6    5    5    5    9    6    4    4    6    5    9    5    7    7
     3    5    5    3    2    5    5    7    5    2    6    6    5    4
     3    6    4    5    5    9    6    5    5    4    2    7    8    5
     4    5    5    2    3    7    4    3    9   10    5    9    6    2
     5    6    7]
 [   0 2297 1392    0    0    0    0    0    0    1    0    0    0    0
     0    0    1    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0    0    1    0
     0    0    1    0    0    1    0    1    0    0    0    0    0    0
     0    0    0    0    0    2    0    0    0    0    1    0    0    1
     0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    3    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    1    1    0    0    0    0
     0    0    0    0    0    0    0    1    0    0    0    0    0    0
     0    1    0]]
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:16<00:00, 26.73it/s]
Average reward: 0.471
Final analysis of results
Actions by count: [   38  6557 17908    24    20    22    20    18    27    22    23    23
    31    17    23    16    19    31    15    22    20    14    20    23
    20    20    26    15    17    29    17    18    18    25    15    15
    21    16    25    13    19    20    22    25    22    20    25    22
    20    19    18    29    22    22    22    24    18    21    25    19
    16    17    19    24    19    26    22    20    33    16    22    17
    24    18    23    31    21    19    14    20    20    21    23    21
    24    21    25    20    17    18    26    26    12    17    18    20
    24    23    16    32    23    17    18    23    28    20    22    18
    12    23    29    22    14    16    22    20    25    20    20    20
    27    23    16    25    19    11    24    21    27]
Successrate by action: [0.         0.58517615 0.62620058 0.         0.         0.
 0.05       0.         0.         0.04545455 0.         0.04347826
 0.03225806 0.         0.         0.         0.10526316 0.
 0.         0.         0.         0.         0.         0.
 0.         0.05       0.         0.         0.         0.
 0.05882353 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.05263158 0.
 0.         0.04       0.04545455 0.05       0.         0.04545455
 0.         0.05263158 0.         0.         0.         0.04545455
 0.         0.         0.         0.         0.         0.
 0.0625     0.11764706 0.         0.04166667 0.         0.
 0.09090909 0.         0.         0.0625     0.         0.
 0.         0.         0.         0.03225806 0.         0.
 0.         0.05       0.         0.04761905 0.         0.
 0.         0.         0.12       0.1        0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.0625     0.03125    0.         0.
 0.         0.         0.         0.         0.04545455 0.05555556
 0.         0.         0.         0.04545455 0.         0.
 0.         0.         0.         0.15       0.         0.05
 0.         0.         0.         0.         0.         0.09090909
 0.         0.14285714 0.03703704]
Matrix of actions vs outcomes, outcome is row, action is column
[[   38  2720  6694    24    20    22    19    18    27    21    23    22
     30    17    23    16    17    31    15    22    20    14    20    23
     20    19    26    15    17    29    16    18    18    25    15    15
     21    16    25    13    18    20    22    24    21    19    25    21
     20    18    18    29    22    21    22    24    18    21    25    19
     15    15    19    23    19    26    20    20    33    15    22    17
     24    18    23    30    21    19    14    19    20    20    23    21
     24    21    22    18    17    18    26    26    12    17    18    20
     24    23    15    31    23    17    18    23    28    20    21    17
     12    23    29    21    14    16    22    20    25    17    20    19
     27    23    16    25    19    10    24    18    26]
 [    0  3837 11214     0     0     0     1     0     0     1     0     1
      1     0     0     0     2     0     0     0     0     0     0     0
      0     1     0     0     0     0     1     0     0     0     0     0
      0     0     0     0     1     0     0     1     1     1     0     1
      0     1     0     0     0     1     0     0     0     0     0     0
      1     2     0     1     0     0     2     0     0     1     0     0
      0     0     0     1     0     0     0     1     0     1     0     0
      0     0     3     2     0     0     0     0     0     0     0     0
      0     0     1     1     0     0     0     0     0     0     1     1
      0     0     0     1     0     0     0     0     0     3     0     1
      0     0     0     0     0     1     0     3     1]]
----------Improved Adaptive Recommender --------
---- Testing with only two treatments ----
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 278.22it/s]
Average reward: 0.411
Final analysis of results
Actions by count: [51 49]
Successrate by action: [0.01960784 0.91836735]
Matrix of actions vs outcomes, outcome is row, action is column
[[50  4]
 [ 1 45]]
Logistic Recommenders: 2
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:01<00:00, 292.60it/s]
Average reward: 0.424
Final analysis of results
Actions by count: [229 246]
Successrate by action: [0.00873362 0.90650407]
Matrix of actions vs outcomes, outcome is row, action is column
[[227  23]
 [  2 223]]
Logistic Recommenders: 2
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:05<00:00, 257.57it/s]
Average reward: 0.420
Final analysis of results
Actions by count: [929 958]
Successrate by action: [0.01399354 0.91544885]
Matrix of actions vs outcomes, outcome is row, action is column
[[916  81]
 [ 13 877]]
Logistic Recommenders: 2
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:30<00:00, 175.31it/s]
Average reward: 0.437
Final analysis of results
Actions by count: [3527 3668]
Successrate by action: [0.01417635 0.93565976]
Matrix of actions vs outcomes, outcome is row, action is column
[[3477  236]
 [  50 3432]]
Logistic Recommenders: 2
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:05<00:00, 65.35it/s]
Average reward: 0.452
Final analysis of results
Actions by count: [13095 14052]
Successrate by action: [0.01718213 0.94769428]
Matrix of actions vs outcomes, outcome is row, action is column
[[12870   735]
 [  225 13317]]
Logistic Recommenders: 2
--- Testing with an additional experimental treatment and 126 gene silencing treatments ---
Setting up simulator
Setting up policy
Fitting historical data to the policy
Running online tests
Number of tests: 100
Testing for  100 steps
100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 254.25it/s]
Average reward: 0.342
Final analysis of results
Actions by count: [ 2 45  1  1  2  1  1  1  1  2  1  1  1  1  2  1  1  1  1  1  1  1  2  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0
  0  0  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0
  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0  0  0  0  0  0
  1  0  0  0  0  0  0  0  0]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:375: RuntimeWarning: invalid value encountered in true_divide
  print("Successrate by action: {}".format(success_by_action / actioncounts))
Successrate by action: [0.5        0.95555556 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.                nan        nan        nan        nan        nan
        nan        nan 0.         0.         0.                nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan 0.                nan        nan        nan
        nan        nan        nan        nan        nan        nan
        nan        nan        nan 0.         0.                nan
        nan 0.                nan        nan        nan        nan
        nan        nan        nan        nan        nan        nan
 0.                nan        nan        nan        nan        nan
        nan        nan        nan]
/mnt/c/Users/aleks/Dropbox/A-University/UiO/2018H/in-stk5000/ml-society-science/src/project-2/recommender.py:376: RuntimeWarning: invalid value encountered in true_divide
  mean_r = (success_by_action-0.1*actioncounts) / actioncounts
Matrix of actions vs outcomes, outcome is row, action is column
[[ 1  2  1  1  2  1  1  1  1  2  1  1  1  1  2  1  1  1  1  1  1  1  2  1
   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
   1  1  1]
 [ 1 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0  0  0]]
Logistic Recommenders: 2
Number of tests: 375
Testing for  375 steps
100%|█████████████████████████████████████████████████████████████████████████████| 375/375 [00:01<00:00, 246.47it/s]
Average reward: 0.460
Final analysis of results
Actions by count: [  6 235  28   2   2   2   3   2   2   2   2   2   2   3   2   2   2   2
   2   2   2   3   2   2   2   2   2   3   2   2   2   2   2   2   2   2
   2   2   2   2   2   2   2   2   2   2   2   3   2   2   2   2   2   2
   2   2   2   2   2   2   2   2   2   2   1   1   2   2   1   2   1   1
   1   1   1   1   1   2   1   1   1   1   1   1   1   2   2   2   1   1
   1   1   1   1   1   1   1   1   1   2   1   1   1   1   1   1   1   4
   1   1   1   1   1   1   1   1   2   1   1   1   1   1   1   1   2   1
   1   2   1]
Successrate by action: [0.5        0.97446809 0.78571429 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  3   6   6   2   2   2   3   2   2   2   2   2   2   3   2   2   2   2
    2   2   2   3   2   2   2   2   2   3   2   2   2   2   2   2   2   2
    2   2   2   2   2   2   2   2   2   2   2   3   2   2   2   2   2   2
    2   2   2   2   2   2   2   2   2   2   1   1   2   2   1   2   1   1
    1   1   1   1   1   2   1   1   1   1   1   1   1   2   2   2   1   1
    1   1   1   1   1   1   1   1   1   2   1   1   1   1   1   1   1   4
    1   1   1   1   1   1   1   1   2   1   1   1   1   1   1   1   2   1
    1   2   1]
 [  3 229  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]]
Logistic Recommenders: 3
Number of tests: 1412
Testing for  1412 steps
100%|███████████████████████████████████████████████████████████████████████████| 1412/1412 [00:05<00:00, 242.65it/s]
Average reward: 0.559
Final analysis of results
Actions by count: [ 18 872 340   6   5   5   5   6   5   5   5   6   5   6   5   5   5   5
   5   8   5   6   5   6   5   7   5   7   5   6   6   5   6   5   5   5
   5   6   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5
   5   5   5   5   5   5   5   5   5   6   5   5   6   5   6   6   5   5
   5   6   8   5   5   6   5   7   5   5   5   5   5   5   5   6   5   5
   5   5   6   5   5   5   5   6   5   5   5   5   6   5   5   5   5   7
   6   5   6   5   5   5   5   5   5   5   4   4   4   5   4   4   4   4
   4   4   5]
Successrate by action: [0.66666667 0.98050459 0.91470588 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.125      0.         0.         0.         0.
 0.         0.14285714 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.125      0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.16666667 0.         0.         0.
 0.         0.16666667 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[  6  17  29   6   5   5   5   6   5   5   5   6   5   6   5   5   5   5
    5   7   5   6   5   6   5   6   5   7   5   6   6   5   6   5   5   5
    5   6   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5
    5   5   5   5   5   5   5   5   5   6   5   5   6   5   6   6   5   5
    5   6   7   5   5   6   5   7   5   5   5   5   5   5   5   6   5   5
    5   5   5   5   5   5   5   5   5   5   5   5   6   5   5   5   5   7
    6   5   6   5   5   5   5   5   5   5   4   4   4   5   4   4   4   4
    4   4   5]
 [ 12 855 311   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0]]
Logistic Recommenders: 8
Number of tests: 5308
Testing for  5308 steps
100%|███████████████████████████████████████████████████████████████████████████| 5308/5308 [00:33<00:00, 129.83it/s]
Average reward: 0.578
Final analysis of results
Actions by count: [1063 3291 1418   10   12    9   14   14   15   13   11   13   13   13
   12   11    9   14   11   12   14   10   10   13   10   14   10   11
   11   11   13   13   13   12   12   12   13    9    9   12    8   10
   11    9   12   11   17   12   10   12   13   13   12   11   13   10
   12   12   10    9   13   10   12   12   12   11   11   12   11   10
    8   11   13   10   17   10   11   16   11   10   10   10   11   10
    9   14   11   11   12    9    9   12    8   13   10   10   10   11
    9   12   11    9   10   12   11    9   13    9   13   12   13    9
   14   11   11   11    9   11    9   13   10   12   11   12   11    9
    9    9   13]
Successrate by action: [0.05644403 0.9881495  0.95345557 0.         0.         0.
 0.         0.         0.06666667 0.         0.         0.
 0.         0.         0.         0.         0.         0.07142857
 0.         0.08333333 0.         0.         0.         0.
 0.         0.07142857 0.         0.         0.         0.
 0.         0.07692308 0.07692308 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.11764706 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.08333333 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.05882353 0.         0.         0.
 0.         0.         0.1        0.         0.         0.
 0.         0.07142857 0.         0.         0.         0.
 0.         0.         0.125      0.         0.         0.
 0.         0.09090909 0.         0.         0.         0.
 0.         0.08333333 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.09090909 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.        ]
Matrix of actions vs outcomes, outcome is row, action is column
[[1003   39   66   10   12    9   14   14   14   13   11   13   13   13
    12   11    9   13   11   11   14   10   10   13   10   13   10   11
    11   11   13   12   12   12   12   12   13    9    9   12    8   10
    11    9   12   11   15   12   10   12   13   13   12   11   13   10
    12   12   10    9   13   10   12   11   12   11   11   12   11   10
     8   11   13   10   16   10   11   16   11   10    9   10   11   10
     9   13   11   11   12    9    9   12    7   13   10   10   10   10
     9   12   11    9   10   11   11    9   13    9   13   12   13    9
    14   11   11   10    9   11    9   13   10   12   11   12   11    9
     9    9   13]
 [  60 3252 1352    0    0    0    0    0    1    0    0    0    0    0
     0    0    0    1    0    1    0    0    0    0    0    1    0    0
     0    0    0    1    1    0    0    0    0    0    0    0    0    0
     0    0    0    0    2    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    1    0    0    0    0    0    0
     0    0    0    0    1    0    0    0    0    0    1    0    0    0
     0    1    0    0    0    0    0    0    1    0    0    0    0    1
     0    0    0    0    0    1    0    0    0    0    0    0    0    0
     0    0    0    1    0    0    0    0    0    0    0    0    0    0
     0    0    0]]
Logistic Recommenders: 18
Number of tests: 19952
Testing for  19952 steps
100%|██████████████████████████████████████████████████████████████████████████| 19952/19952 [05:31<00:00, 60.24it/s]
Average reward: 0.583
Final analysis of results
Actions by count: [ 5915 12403  5377    19    29    29    35    31    35    32    24    29
    23    29    22    27    19    27    21    31    34    31    37    31
    27    34    32    28    33    27    30    27    22    32    22    24
    33    22    33    29    26    34    26    25    23    27    32    29
    26    28    34    26    26    32    25    26    30    26    19    28
    27    30    22    23    32    30    28    32    20    27    25    30
    24    30    28    24    28    29    22    30    24    22    39    30
    26    28    24    24    31    29    29    34    20    27    26    38
    25    25    24    27    23    25    21    35    25    27    31    35
    34    31    30    24    27    21    30    29    22    17    18    24
    19    26    20    24    26    28    33    30    26]
Successrate by action: [0.03567202 0.99185681 0.97656686 0.         0.         0.
 0.         0.03225806 0.02857143 0.0625     0.04166667 0.
 0.         0.         0.04545455 0.07407407 0.         0.03703704
 0.         0.09677419 0.02941176 0.06451613 0.05405405 0.
 0.         0.05882353 0.03125    0.03571429 0.03030303 0.03703704
 0.         0.03703704 0.04545455 0.         0.         0.
 0.         0.         0.         0.         0.03846154 0.
 0.         0.         0.         0.03703704 0.09375    0.
 0.         0.         0.05882353 0.         0.         0.
 0.         0.         0.         0.         0.         0.03571429
 0.         0.03333333 0.         0.04347826 0.         0.03333333
 0.         0.         0.         0.         0.         0.
 0.         0.         0.03571429 0.         0.         0.
 0.         0.         0.08333333 0.         0.02564103 0.03333333
 0.         0.03571429 0.         0.         0.         0.
 0.         0.         0.05       0.         0.         0.
 0.         0.04       0.08333333 0.         0.         0.
 0.         0.08571429 0.         0.         0.         0.02857143
 0.         0.         0.         0.04166667 0.         0.
 0.03333333 0.03448276 0.04545455 0.         0.         0.
 0.         0.         0.         0.04166667 0.03846154 0.
 0.03030303 0.1        0.03846154]
Matrix of actions vs outcomes, outcome is row, action is column
[[ 5704   101   126    19    29    29    35    30    34    30    23    29
     23    29    21    25    19    26    21    28    33    29    35    31
     27    32    31    27    32    26    30    26    21    32    22    24
     33    22    33    29    25    34    26    25    23    26    29    29
     26    28    32    26    26    32    25    26    30    26    19    27
     27    29    22    22    32    29    28    32    20    27    25    30
     24    30    27    24    28    29    22    30    22    22    38    29
     26    27    24    24    31    29    29    34    19    27    26    38
     25    24    22    27    23    25    21    32    25    27    31    34
     34    31    30    23    27    21    29    28    21    17    18    24
     19    26    20    23    25    28    32    27    25]
 [  211 12302  5251     0     0     0     0     1     1     2     1     0
      0     0     1     2     0     1     0     3     1     2     2     0
      0     2     1     1     1     1     0     1     1     0     0     0
      0     0     0     0     1     0     0     0     0     1     3     0
      0     0     2     0     0     0     0     0     0     0     0     1
      0     1     0     1     0     1     0     0     0     0     0     0
      0     0     1     0     0     0     0     0     2     0     1     1
      0     1     0     0     0     0     0     0     1     0     0     0
      0     1     2     0     0     0     0     3     0     0     0     1
      0     0     0     1     0     0     1     1     1     0     0     0
      0     0     0     1     1     0     1     3     1]]
Logistic Recommenders: 48
